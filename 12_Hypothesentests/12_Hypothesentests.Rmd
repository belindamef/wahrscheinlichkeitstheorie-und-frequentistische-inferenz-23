---
fontsize: 8pt
bibliography: 12_Referenzen.bib
citation_package: natbib
output:
  beamer_presentation:
    keep_tex: true
    includes:
      in_header: 12_header.tex
---


```{r, include = F}
source("12_R_common.R")
fdir        = file.path(getwd(), "12_Abbildungen")                               # Abbildungsverzeichnis
```


#  {.plain}
\center
```{r, echo = FALSE, out.width = "20%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_otto.png")
```

\vspace{2mm}

\Large
Wahrscheinlichkeitstheorie und Frequentistische Inferenz
\vspace{6mm}

\large
BSc Psychologie WiSe 2021/22

\vspace{6mm}
\normalsize
Prof. Dr. Dirk Ostwald


#  {.plain}
\vfill
\center
\huge
\textcolor{black}{(12) Hypothesentests}
\vfill

#
```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_frequentistische_inferenz.pdf")
```

#
```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_frequentistische_inferenz_hypothesentests.pdf")
```

#
\textcolor{darkblue}{Standardannahmen Frequentistischer Inferenz}

\footnotesize
$\mathcal{M}$ sei ein statistisches Modell mit Stichprobe $\ups_1,...,\ups_n  \sim p_\theta$.
**Es wird angenommen, dass ein konkret vorliegender Datensatz $y = (y_1,...,y_n) \in \mathbb{R}^n$
eine der möglichen Realisierungen von $\ups_1,...,\ups_n \sim p_\theta$ ist.**
Aus Frequentistischer Sicht kann man eine Studie unter gleichen Umständen unendlich
oft wiederholen und zu jedem Datensatz Schätzer oder Statistiken auswerten, z.B. das Stichprobenmittel:

\footnotesize
\begin{itemize}
\item[] Datensatz (1) : $y^{(1)} = \left(y_1^{(1)}, y_2^{(1)}, ...,y_n^{(1)}\right)$
						mit $\bar{y}_n^{(1)} = \frac{1}{n}\sum_{i=1}^n y_i^{(1)}$
\item[] Datensatz (2) : $y^{(2)} = \left(y_1^{(2)}, y_2^{(2)}, ...,y_n^{(2)}\right)$
                        mit $\bar{y}_n^{(2)} = \frac{1}{n}\sum_{i=1}^n y_i^{(2)}$
\item[] Datensatz (3) : $y^{(3)} = \left(y_1^{(3)}, y_2^{(3)}, ...,y_n^{(3)}\right)$
                        mit $\bar{y}_n^{(3)} = \frac{1}{n}\sum_{i=1}^n y_i^{(3)}$
\item[] Datensatz (4) : $y^{(4)} = \left(y_1^{(4)}, y_2^{(4)}, ...,y_n^{(4)}\right)$
                        mit $\bar{y}_n^{(4)} = \frac{1}{n}\sum_{i=1}^n y_i^{(4)}$
\item[] Datensatz (5) : $y^{(5)} = ...$
\end{itemize}

Um die Qualität statistischer Methoden zu beurteilen betrachtet die Frequentistische
Statistik deshalb die Wahrscheinlichkeitsverteilungen von Schätzern und Statistiken
unter Annahme von $\ups_1,...,\ups_n \sim p_\theta$. Was zum Beispiel
ist die Verteilung der $\bar{y}_n^{(1)}$, $\bar{y}_n^{(2)}$, $\bar{y}_n^{(3)}$, $\bar{y}_n^{(4)}$, ...
also die Verteilung der Zufallsvariable $\bar{\ups}$?

Wenn eine statistische Methode im Sinne der Frequentistischen Standardannahmen "gut" ist, dann heißt das
also, dass sie bei häufiger Anwendung "im Mittel gut" ist. Im Einzelfall, also
im Normalfall nur eines vorliegenden Datensatzes, kann sie auch "schlecht" sein.

#
\textcolor{darkblue}{Grundlegende Logik Frequentistischer Hypothesentests}

\footnotesize
\justifying Man hat einen Datensatz $y_1,...,y_n$ vorliegen und nimmt an, dass es sich
dabei um die Realisation einer Stichprobe handelt, zum Beispiel von $\ups_1,...,\ups_n \sim
N(\mu,\sigma^2)$.

Man berechnet basierend auf dem Datensatz eine *Teststatistik*, zum Beispiel
das anhand der Stichprobenvarianz und der Stichprobengröße normalisierte
Stichprobenmittel $\sqrt{n}\bar{y}_n/s_n$.

Man fragt sich, wie wahrscheinlich es wäre, den beobachteten oder
einen extremeren Wert der Teststatistik unter der Annahme eines *Nullmodels*
zu observieren. Dabei meint man mit *Nullmodell* intuitiv ein Wahrscheinlichkeitsverteilungsmodell
bei dem kein "interessanter Effekt" vorliegt, also zum Beispiel $\mu = 0$ gilt.
Die Wahrscheinlichkeit ist wie immer Frequentistisch zu verstehen, d.h. als
idealisierte relative Häufigkeit, wenn man viele Stichprobenrealisationen des
Nullmodels generieren würde.

Ist die betrachtete Wahrscheinlichkeit dafür, den beobachteten oder einen
extremeren Wert der Teststatistik unter Annahme des Nullmodells zu observieren
groß, so sagt man sich "Nunja, dann ist es wohl ganz plausibel,
dass das Nullmodel die Daten generiert hat". Im Wissenschaftsjargon spricht man
von einem "nicht-signifikanten Ergebnis".

Ist die betrachtete Wahrscheinlichkeit dafür, den beobachteten oder einen
extremeren Wert der Teststatistik unter Annahme des Nullmodells zu observieren
dagegen klein, so sagt man sich "Aha, dann ist es wohl nicht so plausibel, dass
das Nullmodel die Daten generiert hat". Im Wissenschaftsjargon spricht man von einem
"signifikanten Ergebnis".

Wie immer in der Frequentistischen Statistik weiß man nach Durchführung dieser
Prozedur nicht, ob im vorliegenden Fall nun wirklich das Nullmodel oder ein
anderes Modell die Daten generiert hat, sondern man weiß nur, wie oft man bei
dieser Prozedur im Mittel richtig oder falsch liegen würde, wenn alle Annahmen
zuträfen und man diese Prozedur sehr oft wiederholen würde.

#
\setstretch{2.4}
\large
\vfill
Grundlegende Definitionen

Einstichproben-T-Test

p-Werte

Konfidenzintervalle und Hypothesentests

Anwendungsbeispiel

Selbstkontrollfragen
\vfill

#
\setstretch{2.4}
\large
\vfill
**Grundlegende Definitionen**

Einstichproben-T-Test

p-Werte

Konfidenzintervalle und Hypothesentests

Anwendungsbeispiel

Selbstkontrollfragen
\vfill

# Grundlegende Definitionen
\small
\begin{definition}[Statistische Hypothesen und Testszenario]
\justifying
$\ups_1,...,\ups_n \sim p_\theta$ sei eine Stichprobe mit WMF oder WDF $p_\theta$,
$\mathcal{Y}$ sei der Ergebnisraum des Zufallsvektors $\ups := (\ups_1,...,\ups_n)$, und
$\Theta$ sei der Parameterraum des zugrundeliegenden statistischen Modells.
Weiterhin sei $\{\Theta_0,\Theta_1\}$ eine Partition des Parameterraumes, so
dass $\Theta = \Theta_0 \cup \Theta_1$ und $\Theta_0 \cap \Theta_1 = \emptyset$
gelten. Eine \textit{statistische Hypothese} ist dann eine Aussage über den
wahren, aber unbekannten, Parameterwert $\theta$ in Hinblick auf die Untermengen
$\Theta_0$ und $\Theta_1$ des Parameterraums. Speziell werden die Aussagen
\begin{itemize}
\item $\theta \in \Theta_0$ als \textit{Nullhypothese} $H_0$
\item $\theta \in \Theta_1$ als \textit{Alternativhypothese} $H_1$
\end{itemize}
bezeichnet. Die Einheit aus Stichprobe, Ergebnisraum, Parameterraum, und
Hypothesen wird im Folgenden als \textit{Testszenario} bezeichnet.
\end{definition}

# Grundlegende Definitionen
\small
\begin{definition}[Einfache und zusammengesetzte Hypothesen]
\justifying
Für statistische Hypothesen $\Theta_i,i = 0,1$ gilt:
\begin{itemize}
\item Enthält $\Theta_i$ nur ein einziges Element, so heißt $\Theta_i$ \textit{einfach}.
\item Enthält $\Theta_i$ mehr als ein Element, so heißt $\Theta_i$ \textit{zusammengesetzt}.
\end{itemize}
\end{definition}

Bemerkungen

* Die Nullhypothese $\Theta_0 = \{0\}$ ist ein Beispiel für eine einfache Hypothese.
* Bei einer einfachen Hypothese ist die Wahrscheinlichkeitsverteilung von $\ups$ genau festgelegt.
* Bei einer zusammengesetzten Hypothese ist nur die Verteilungsklasse von $\ups$ festgelegt.

# Grundlegende Definitionen
\small
\setstretch{1.2}

\begin{definition}[Einseitige und zweiseitige Hypothesen]
\justifying
$\Theta := \mathbb{R}$ sei ein eindimensionaler Parameterraum und $\theta_0$
sei ein Element von $\Theta$. Dann werden zusammengesetzte Nullhypothesen der
Form
\begin{equation}
\Theta_0 := ]-\infty,\theta_0] \mbox{ oder }
\Theta_0 := [\theta_0,\infty[
\end{equation}
\textit{einseitige Nullhypothesen} genannt und auch in der Form
\begin{equation}
H_0 : \theta \le \theta_0 \mbox{ oder } H_0 : \theta \ge \theta_0
\end{equation}
geschrieben. Die entsprechenden Alternativhypothesen haben dabei die Form
\begin{equation}
\Theta_1 := ]\theta_0,\infty[ \mbox{ oder } \Theta_1 := ]-\infty, \theta_0[
\mbox{ bzw. }  H_1 : \theta > \theta_0 \mbox{ oder } H_1 : \theta < \theta_0.
\end{equation}
Bei einer einfachen Nullhypothese der Form
\begin{equation}
\Theta_0 := \{\theta_0\} \mbox{ bzw. } H_0 : \theta = \theta_0
\end{equation}
wird die Alternativhypothese
\begin{equation}
\Theta_1 := \Theta \setminus \{\theta_0\} \mbox{ bzw. } H_1 : \theta \neq \theta_0
\Leftrightarrow \Theta_1 := ]-\infty, \theta_0[\,\, \cup \,\,]\theta_0,\infty[
\end{equation}
\textit{zweiseitige Alternativhypothese} genannt.
\end{definition}

# Grundlegende Definitionen
\small
\begin{definition}[Test]
\justifying
In einem Testszenario ist ein \textit{Test} $\phi$ eine Abbildung aus dem
Ergebnisraum $\mathcal{Y}$ nach $\{0,1\}$,
\begin{equation}
\phi : \mathcal{Y} \to \{0,1\}, y \mapsto \phi(y).
\end{equation}
Dabei repräsentiert
\begin{itemize}
\item $\phi(y) = 0$ den Vorgang des Nichtablehnens der Nullhypothese.
\item $\phi(y) = 1$ den Vorgang des Ablehnens der Nullhypothese.
\end{itemize}
\end{definition}

\footnotesize
Bemerkung

* Weil $y$ eine Realisation von $\ups$ ist, ist $\phi(y)$ eine Realisation von $\phi(\ups)$.

# Grundlegende Definitionen
\small
\begin{definition}[Standardtest]
\justifying
Ein \textit{Standardtest} ist definiert durch die Verkettung einer
\textit{Teststatistik}
\begin{equation}
\gamma : \mathcal{Y} \to \mathbb{R}
\end{equation}
und einer \textit{Entscheidungsregel}
\begin{equation}
\delta : \mathbb{R} \to \{0,1\}.
\end{equation}
Ein Standardtest kann also geschrieben werden als
\begin{equation}
\phi := \delta \circ \gamma : \mathcal{Y} \to \{0,1\}.
\end{equation}
\end{definition}

\footnotesize
Bemerkungen

* Weil $y$ eine Realisation von $\ups$ ist, ist $\gamma(y) \in \mathbb{R}$ eine Realisation von $\gamma(\ups)$.
* Weil $\gamma(y)$ eine Realisation von $\gamma(\ups)$ ist, ist $(\delta \circ \gamma)(y)$ eine Realisation von $(\delta \circ \gamma)(\ups)$.
* Wir betrachten in der Folge nur Standardtests.

# Grundlegende Definitionen
\small
\begin{definition}[Kritischer Bereich]
\justifying
Die Untermenge $K$ des Ergebnisraums des Zufallsvektors $\ups := (\ups_1,...,\ups_n)$,
für die ein Test den Wert 1 annimmt, heißt \textit{kritischer Bereich} des Tests,
\begin{equation}
K := \{y \in \mathcal{Y} |\phi(y) = 1 \} \subset \mathcal{Y}.
\end{equation}
\end{definition}
Bemerkungen

* Die Ereignisse $\{\phi(\ups) = 1\}$ und $\{\ups\in K\}$ sind äquivalent.
* Die Ereignisse $\{\phi(\ups) = 1\}$ und $\{\ups\in K\}$ haben die gleiche Wahrscheinlichkeit.

# Grundlegende Definitionen
\small
\begin{definition}[Ablehnungsbereich]
\justifying
Die Untermenge $A$ des Ergebnisraums einer Teststatistik, für die der Test
den Wert 1 annimmt, heißt \textit{Ablehnungsbereich} des Tests,
\begin{equation}
A := \{\gamma(y) \in \mathbb{R} |\phi(y) = 1 \} \subset \mathbb{R}.
\end{equation}
\end{definition}
Bemerkungen

* Die Ereignisse $\{\phi(\ups) = 1\}$ und $\{\gamma(\ups) \in A\}$ sind äquivalent.
* Die Ereignisse $\{\phi(\ups) = 1\}$ und $\{\gamma(\ups) \in A\}$ haben die gleiche Wahrscheinlichkeit.

# Grundlegende Definitionen
\small
\begin{definition}[Kritischer Wert-basierte Tests]
\justifying
Ein \textit{kritischer Wert-basierter Test} ist ein Standardtest, bei dem die
Entscheidungsregel $\delta$ von einem kritischen Wert $k \in \mathbb{R}$ abhängt.
Speziell ist
\begin{itemize}
\item ein \textit{einseitiger kritischer Wert-basierter Test} von der Form
\begin{equation}
\phi : \mathcal{Y} \to \{0,1\}, y \mapsto \phi(y) := 1_{\{\gamma(y) \ge k\}} =
\begin{cases}
1 & \gamma(y) \ge k \\
0 & \gamma(y) < k
\end{cases}
\end{equation}
\item ein \textit{zweiseitiger kritischer Wert-basierter Test} von der Form
\begin{equation}
\phi : \mathcal{Y} \to \{0,1\}, y \mapsto \phi(y) := 1_{\{|\gamma(y)| \ge k\}} =
\begin{cases}
1 & |\gamma(y)| \ge k \\
0 & |\gamma(y)| < k
\end{cases}
\end{equation}
\end{itemize}
\end{definition}

Bemerkung

* Wir betrachten in der Folge nur kritischer Wert-basierte Tests.

# Grundlegende Definitionen
\small
\begin{definition}[Richtige Testentscheidungen und Testfehler]
\justifying
Das Nichtablehnen der Nullhypothese, wenn die Nullhypothese zutrifft werden,
sowie das Ablehnen der Nullhypothese, wenn die Nullhypothese nicht zutrifft,
werden \textit{richtige Testentscheidungen} genannt. Es können weiterhin zwei
Arten von Testfehlern auftreten: das Ablehnen der Nullhypothese, wenn die
Nullhypothese zutrifft, heißt \textit{Typ I Fehler}, das Nichtablehnen der
Nullhypothese, wenn die Alternativhypothese zutrifft, heißt
\textit{Typ II Fehler}.
\end{definition}
Die untenstehende Graphik gibt eine Übersicht.
\vspace{1mm}

```{r, echo = FALSE, out.width = "55%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_testfehler.pdf")
```


# Grundlegende Definitionen
\small
\begin{definition}[Testgütefunktion]
\justifying
Für einen Test $\phi$ ist die \textit{Testgütefunktion} definiert als
\begin{equation}
q_{\phi} : \Theta \to [0,1], \theta \mapsto q_{\phi}(\theta) := \mathbb{P}_\theta(\phi = 1).
\end{equation}
Für $\theta \in \Theta_1$ heißt $q_\phi$ auch \textit{Powerfunktion} oder
\textit{Trennschärfefunktion}.
\end{definition}
\footnotesize
Bemerkungen

* Wir verzichten hier und im Folgenden auf die explizite Notation der Abhängigkeit von $\phi$ von $\ups$.
* $\mathbb{P}_\theta$ bezeichnet die Verteilung von $\phi$ unter der Annahme $\ups_1,...,\ups_n \sim p_\theta$.
* Es gilt $\mathbb{P}_\theta(\phi = 1) = \mathbb{P}_\theta (\ups \in K) = \mathbb{P}_\theta(\gamma \in A)$
* Für jedes $\theta \in \Theta$ liefert $q_\phi$ die Wahrscheinlichkeit, dass $H_0$ durch $\phi$ abgelehnt wird.
* Bei Poweranalysen betrachtet man $q_{\phi}$ als Funktion aller Testszenario und Testparameter.
* Ändert sich $\phi$, z.B. weil sich der kritische Wert von $\phi$ ändert, dann ändert sich $q_{\phi}(\theta)$.
* Im Idealfall hätte man einen Test $\phi$ mit
\begin{equation}
q_\phi(\theta) = \mathbb{P}_\theta(\phi = 1) = 0 \mbox{ für } \theta \in \Theta_0 \mbox{ und }
q_\phi(\theta) = \mathbb{P}_\theta(\phi = 1) = 1 \mbox{ für } \theta \in \Theta_1.
\end{equation}
* Die Testentscheidung eines solchen $\phi$ wäre mit Wahrscheinlichkeit 1 richtig.


# Grundlegende Definitionen
\textcolor{darkblue}{Intuition zur Testkonstruktion}
\small

Im Idealfall hätte man einen Test $\phi$ mit
\begin{equation}
q_\phi(\theta) = \mathbb{P}_\theta(\phi = 1) = 0 \mbox{ für } \theta \in \Theta_0 \mbox{ und }
q_\phi(\theta) = \mathbb{P}_\theta(\phi = 1) = 1 \mbox{ für } \theta \in \Theta_1.
\end{equation}

$\Rightarrow$ Gut sind kleine Werte von $q_\phi$ für $\theta \in \Theta_0$
und große Werte von $q_\phi$ für $\theta \in \Theta_1$.

Generell gibt es Abhängigkeiten zwischen den Werten von $q_\phi$ für
$\theta \in \Theta_0$ und $\theta \in \Theta_1$:

\footnotesize
Sei zum Beispiel $\phi_a$ der Test definiert durch $\phi_a(y) := 0$
für alle $y \in \mathcal{Y}$, also der Test, der die Nullhypothese, unabhängig
von den beobachteten Daten, \textit{niemals ablehnt}. Für diesen Test gilt
$q_{\phi_a}(\theta) = 0$ für $\theta \in \Theta_0$. Allerdings gilt für diesen
Test auch $q_{\phi_a}(\theta) = 0$ für $\theta \in \Theta_1$.

Andersherum sei $\phi_b$ der Test definiert durch $\phi_b(y) := 1$
für alle $y \in \mathcal{Y}$, also ein Test, der die Nullhypothese, unabhängig
von den beobachteten Daten, \textit{immer ablehnt}. Für diesen Test gilt
$q_{\phi_b}(\theta) = 1$ für $\theta \in \Theta_1$. Allerdings gilt für diesen
Test auch  $q_{\phi_b}(\theta) = 1$ für $\theta \in \Theta_0$.

\small
In der Konstruktion eines Tests muss also eine angemessene Balance zwischen
kleinen Werten von $q_\phi$  für $\theta \in \Theta_0$ und großen Werten von
$q_\phi$ für $\theta \in \Theta_1$ gefunden werden.

# Grundlegende Definitionen
\textcolor{darkblue}{Intuition zur Testkonstruktion}
\small

Die populärste Methode, eine Balance zwischen zwischen kleinen Werten von
$q$  für $\theta \in \Theta_0$ und großen Werten von $q$ für $\theta \in \Theta_1$
zu finden, ist in einem ersten Schritt ein $\alpha_0 \in [0,1]$ zu wählen und
sicher zu stellen, dass
\begin{equation}\label{eq:significance}
q_\phi(\theta) \le \alpha_0 \mbox{ für alle } \theta \in \Theta_0.
\end{equation}

Eine konventionelle Wahl für sein solches $\alpha_0$ ist zum Beispiel $\alpha_0 := 0.05$.

Unter allen Tests und statistischen Modellen, die Ungleichung \eqref{eq:significance} erfüllen,
wird man dann einen Test oder ein statistisches Modell auswählen, so dass $q_\phi(\theta)$ für
$\theta \in \Theta_1$ so groß wie möglich ist.

Dieses Vorgehen ist nicht alternativlos, man kann zum Beispiel auch lineare
Kombinationen verschiedener Fehlerwahrscheinlichkeiten minimieren. Es ist aber
das in der Anwendung populärste Vorgehen. Wir werden uns deshalb in der Folge auf
dieses Vorgehen beschränken.

Das beschriebene Vorgehen motiviert die folgenden Definitionen der Begriffe
des Level-$\alpha_0$-Tests, des Signifikanzlevels $\alpha_0$ (oft auch als
*Signifikanzlevel* bezeichnet) und des Testumfangs $\alpha$ (auch als *effektives Niveau*
bezeichnet).

# Grundlegende Definitionen
\small
\begin{definition}[Level-$\alpha_0$-Test, Signifikanzlevel $\alpha_0$,
Testumfang $\alpha$]
$q_\phi$ sei die Testgütefunktion eines Tests $\phi$ und es sei
$\alpha_0 \in [0,1]$. Dann heißt ein Test $\phi$, für den gilt, dass
\begin{equation}
q_\phi(\theta) \le \alpha_0 \mbox{ für alle } \theta \in \Theta_0
\end{equation}
ein \textit{Level-$\alpha_0$-Test} und man sagt, dass der Test das
\textit{Signifikanzlevel $\alpha_0$} hat. Die Zahl
\begin{equation}
\alpha := \max_{\theta \in \Theta_0} q_\phi(\theta) \in [0,1]
\end{equation}
heißt der \textit{Testumfang} von $\phi$.
\end{definition}

Bemerkungen

* $\alpha$ ist die größtmögliche Wahrscheinlichkeit für einen Typ I Fehler.
* Ein Test ist dann, und nur dann, ein Level-$\alpha_0$-Test, wenn $\alpha \le \alpha_0$ gilt.
* Bei einer einfachen Nullhypothese gilt für den Testumfang, dass $\alpha = q_{\phi}(\theta_0) = \mathbb{P}_{\theta_0}(\phi = 1)$.


# Grundlegende Definitionen
\textcolor{darkblue}{Typ I Fehlerwahrscheinlichkeit vs. Testumfang vs. Signifikanzlevel}

\small
Bei einfacher $\Theta_0$ ist der Testumfang gleich der Wahrscheinlichkeit
eines Typ I Fehlers
\begin{equation}
\alpha
:= \max_{\theta \in \Theta_0} q_\phi(\theta)
=  \max_{\theta \in \{\theta_0\}} q_\phi(\theta)
= q_\phi(\theta_0)
= \mathbb{P}_{\theta_0}(\phi = 1).
\end{equation}

Bei zusammengesetzter $\Theta_0$ gibt es je nach Wert von $\theta \in \Theta_0$ verschiedene Wahrscheinlichkeiten
für einen Typ I Fehler. Die größte dieser Wahrscheinlichkeiten ist der
Testumfang
\begin{equation}
\alpha
:= \max_{\theta \in \Theta_0} q_\phi(\theta)
 = \max_{\theta \in \Theta_0} \mathbb{P}_{\theta}(\phi = 1).
\end{equation}

Ein Test hat Signifikanzlevel $\alpha_0$, wenn der Testumfang kleiner
oder gleich $\alpha_0$ ist.
\begin{equation}
\alpha
=   \max_{\theta \in \Theta_0} q_\phi(\theta)
\le \alpha_0
\end{equation}

Ein Test, bei dem das Signifikanzlevel größer als der Testumfang ist, heißt *konsvervativ*.

Ein Test, bei dem das Signifikanzlevel gleich dem Testumfang ist, heißt *exakt*.

# Grundlegende Definitionen

\textcolor{darkblue}{Zur Wahl von Nullhypothese und Alternativhypothese}

\small
Das Vorgehen in der Testkonstruktion zunächst durch die Wahl
eines Signifikanzlevels den Testumfang zu begrenzen und erst in einem zweiten
Schritt dafür zu sorgen, dass die Wahrscheinlichkeit von $\phi = 1$ bei $\theta
\in \Theta_1$ bei diesem Signifikanzlevel möglichst groß ist, induziert eine
Asymmetrie in der Behandlung von Null- und Alternativhypothese. Implizit wichtet
man mit diesem Vorgehen Typ I Fehler als schwerwiegender als Typ II Fehler.

Dies wiederum impliziert eine mögliche Strategie zur Festlegung
von Null- und Alternativhypothese: Die Nullhypothese ist die Hypothese,
hinsichtlich deren assoziierter Testentscheidung man eher keinen Fehler machen
möchte bzw. deren Fehlerwahrscheinlichkeit man primär kontrollieren möchte.

In der wissenschaftichen Anwendung ist es Standard, die falsche
Konfirmation der eigenen Theorie als einen schwerwiegenderen Fehler als die
falsche Ablehnung der eigenen Theorie zu werten.

Die falsche Konfirmation der eigenen Theorie sollte also ein Typ I
Fehler, das falsche Ablehnen der eigenen Theorie ein Typ II Fehler sein.

Damit die falsche Konfirmation der eigenen Theorie einen Typ I Fehler, also
das Ablehnen von $H_0$ bei Zutreffen von $H_0$, darstellt, muss die
eigene Theorie als Alternativhypothese aufgestellt werden. Die Alternativhypothese
fälschlichweise Abzulehnen wird damit ein Typ II Fehler.


# Grundlegende Definitionen
\textcolor{darkblue}{Kommentar zum Frequentistischen Hypothesentesten in der Wissenschaft}

\small
Frequentistisches Hypothesentesten ist als Entscheidungsproblem
ohne klar und explizit definierte Entscheidungsnutzenfunktion formuliert und
deshalb recht mühselig zu analysieren und zu studieren. Es gibt sehr viel
zugänglichere Theorien zu Entscheidungen unter Unsicherheit (vgl. @pratt_1995,
@puterman_2005, @ostwald_2015, @horvath_2021)

Oberflächlich betrachtet liefern Hypothesentests einfache binäre
Aussagen der Form "Die Hypothese (Theorie) ist gegeben die Evidenz abzulehnen
oder zu akzeptieren". Solche Aussagen sind im Entscheidungskontext hilfreich,
denn es muss etwas passieren, also eine Entscheidung getroffen werden. In der
Wissenschaft, also der menschlichen Kommunikationsstruktur über die Beschaffenheit
der Welt, muss aber nichts final entschieden, sondern nur das Maß an
Unsicherheit über den gerade vorherrschenden Theoriestand quantifiziert und
kommuniziert werden. Generell sollten Fragestellungen der Grundlagenwissenschaften
deshalb gerade nicht als Entscheidungsprobleme formuliert werden.

Trotz landläufiger Meinung das Bayesianische Herangehensweisen
wie Positive Predictive Values oder Bayes Factors hier irgendwie besser sind,
ist dem nicht so, so lange die mit einer gewissen Modellpräferenz assoziierte
Unsicherheit nicht klar mitkommuniziert wird.

Und trotz alledem ist Frequentistisches Hypothesentesten in der
Wissenschaftscommunity weiterhin sehr populär (wenn auch vermutlich nicht
immer ganz verstanden) und sollte deshalb im Rahmen eines wissenschaftlichen
Studiums wie der Psychologie intellektuell durchdrungen werden.

#
\setstretch{2.4}
\large
\vfill
Grundlegende Definitionen

**Einstichproben-T-Test**

p-Werte

Konfidenzintervalle und Hypothesentests

Anwendungsbeispiel

Selbstkontrollfragen
\vfill

# Einstichproben-T-Test
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_messplan.pdf")
```

# Einstichproben-T-Test
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression
\vspace{2mm}

\small
Für die Pre-Post BDI Score Reduktion $\ups_i$ der $i$ten von $n$ Patient:innen legen wir das Modell
\begin{equation}
\ups_{i} = \mu + \varepsilon_{i} \mbox{ mit } \varepsilon_{i} \sim N(0,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n
\end{equation}
zugrunde. Dabei wird die Pre-Post BDI Reduktion $\ups_i$ der $i$ten Patient:in also mithilfe einer
über die Gruppe von Patient:innen identischen Pre-Post BDI Score Reduktion $\mu \in \mathbb{R}$
und einer Patient:innen-spezifischen normalverteilten Pre-Post BDI Score Reduktionsabweichung
$\varepsilon_{i}$ erklärt

Wie gezeigt ist dieses Modell äquivalent zum Normalverteilungsmodell
\begin{equation}
\ups_1,...,\ups_n \sim N(\mu,\sigma^2).
\end{equation}

$\Rightarrow$ Wir seien nun am Testen einer statistischen Hypothese hinsichtlich $\mu$ interessiert.

$\Rightarrow$ Das betrachtete Anwendungsszenario ist dann ein Beispiel für einen **Eintstichproben-T-Test**.


# Einstichproben-T-Test
Mögliche Hypothesen im Einstichproben-Test-Szenario
\small
\setstretch{1.1}

Einfache Nullhypothese, einfache Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu = \mu_1$
\begin{itemize}
\item Theoretisch wichtiges Szenario (Neymann-Pearson Lemma)
\item Praktische Relevanz eher gering
\end{itemize}

Einfache Nullhypothese, zusammengesetzte Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu \neq \mu_0$
\begin{itemize}
\item Zweiseitiger Einstichproben-T-Test mit ungerichteter Hypothese
\item Ungerichtete Fragestellung nach einem Unterschied
\end{itemize}

Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu \le \mu_0, H_1:\mu > \mu_0$
\begin{itemize}
\item Einseitiger Einstichproben-T-Test mit gerichteter Hypothese
\item Gerichtete Fragestellung nach einem positiven Unterschied
\end{itemize}

Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu\ge\mu_0,H_1:\mu<\mu_0$
\begin{itemize}
\item Gerichtete Fragestellung nach einem negativen Unterschied
\item Qualitativ äquivalente Theorie zum umgekehrten Fall
\end{itemize}

# Einstichproben-T-Test
Hier betrachtete Hypothese des Einstichproben-Test-Szenarios
\small
\setstretch{1.1}

\textcolor{lightgray}{Einfache Nullhypothese, einfache Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu = \mu_1$}
\begin{itemize}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Theoretisch wichtiges Szenario (Neymann-Pearson Lemma)}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Praktische Relevanz eher gering}
\end{itemize}
Einfache Nullhypothese, zusammengesetzte Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu \neq \mu_0$
\begin{itemize}
\item Zweiseitiger Einstichproben-T-Test mit ungerichteter Hypothese
\item Ungerichtete Fragestellung nach einem Unterschied
\end{itemize}
\textcolor{lightgray}{Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu \le \mu_0, H_1:\mu > \mu_0$}
\begin{itemize}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Einseitiger Einstichproben-T-Test mit gerichteter Hypothese}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Gerichtete Fragestellung nach einem positiven Unterschied}
\end{itemize}
\textcolor{lightgray}{Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu\ge\mu_0,H_1:\mu<\mu_0$}
\begin{itemize}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Gerichtete Fragestellung nach einem negativen Unterschied}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Qualitativ äquivalente Theorie zum umgekehrten Fall}
\end{itemize}

# Einstichproben-T-Test
\setstretch{2.4}
\large
Gliederung

\normalsize
(1) Statistisches Modell und Testhypothesen
(2) Definition und Analyse der Teststatistik
(3) Definition des Tests
(4) Analyse der Testgütefunktion
(5) Testumfangkontrolle
(6) Analyse der Powerfunktion

# Einstichproben-T-Test | (1) Statistischem Modell und Testhypothesen
\vspace{2mm}
\small
Das **Statistische Modell des Einstichproben-T-Tests** ist definiert als
\begin{equation}
\ups_i = \mu + \varepsilon_i \mbox{ mit } \varepsilon_i \sim N(0,\sigma^2) \mbox{ für } i = 1,...,n
\end{equation}
wobei

* $\ups_i, i = 1,...,n$ beobachtbare Zufallsvariablen,
* $\mu$ den wahren, aber unbekannten, Erwartungswertparameter der Stichprobenvariablen,
* $\varepsilon_i, i = 1,...,n$ unabhängige normalverteilte nicht-beobachtbare Zufallsvariablen und
* $\sigma^2>0$ den Varianzparameter der $\varepsilon_i$

bezeichnen. Wie unten (erneut) gezeigt, ist dieses Modell äquivalent zum Normalverteilungsmodell
\begin{equation}
\ups = \ups_1,...,\ups_n \sim N(\mu,\sigma^2),
\end{equation}
also der Annahme unabhängig und identisch normalverteilter Stichprobenvariablen
mit Erwartungswertparameter $\mu$ und Varianzparameter $\sigma^2$. Für ein
$\mu_0$ betrachten wir die einfache **Nullhypothese** und die zusammengesetzte **Alternativhypothese**
\begin{equation}
H_0 : \mu = \mu_0 \Leftrightarrow \Theta_0 := \{\mu_0\}
\mbox{ und }
H_1 : \mu \neq \mu_0 \Leftrightarrow \Theta_1 := \mathbb{R} \setminus \{\mu_0\},
\end{equation}
respektive. Bezogen auf das Anwendungsbeispiel ist hier $\mu_0 := 0$ von Interesse:

* $H_0 : \mu = 0$ entspricht der Hypothese keines Effekts der Therapie auf die BDI Score Reduktion.
* $H_1 : \mu \neq 0$ entspricht der Hypothese  eines Effekts der Therapie auf die BDI Score Reduktion.

# Einstichproben-T-Test | (1) Statistisches Modell und Testhypothesen
\footnotesize
\underline{Beweis der Äquivalenz der Modellformen}

Die Äquivalenz beider Modellformen folgt direkt aus der Transformation
normalverteilter Zufallsvariablen durch linear-affine Funktionen (cf. (8)
Transformationen der Normalverteilung). Speziell gilt im vorliegenden Fall für
$\varepsilon_i \sim N(0,\sigma^2)$, dass
\begin{equation}
\ups_i = f(\varepsilon_i)
\mbox{ mit }
f : \mathbb{R} \to \mathbb{R}, \epsilon_i \mapsto f(\epsilon_i) := \epsilon_i + \mu.
\end{equation}
Mit den WDF Transformationstheorem bei linear-affinen Abbildungen folgt dann
\begin{align}
\begin{split}
p_{\ups_i}(y_i)
& = \frac{1}{|1|} p_{\varepsilon_i}\left(\frac{y_i - \mu}{1} \right)                        \\
& = N\left(y_i - \mu; 0, \sigma^2\right)                                                    \\
& = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(y_i - \mu - 0)^2 \right)    \\
& = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(y_i - \mu)^2 \right)        \\
& = N(y_i; \mu,\sigma^2),
\end{split}
\end{align}
also $\ups_i \sim N(\mu,\sigma^2)$.


# Einstichproben-T-Test | (2) Definition und Analyse der Teststatistik
\footnotesize
\begin{definition}[Einstichproben-T-Teststatistik]
\justifying
$\ups_1,...,\ups_n \sim N(\mu,\sigma^2)$ sei die Stichprobe eines Normalverteilungmodells,
$\bar{\ups}$ bezeichne das Stichprobenmittel, $S$ bezeichne die Stichprobenstandardabweichung
und es sei $\mu_0 \in \mathbb{R}$. Dann ist die \textit{T-Teststatistik} definiert als
\begin{equation}
T := \sqrt{n}\left(\frac{\bar{\ups} - \mu_0}{S} \right).
\end{equation}
\end{definition}
Bemerkungen

* Im Gegensatz zur T-Konfidenintervallstatistik muss bei der T-Teststatistik nicht $\mu_0 = \mu$ gelten.
* Intuitiv kann die T-Teststatistik als mit der Stichprobengröße (Evidenz)
gewichtetes Verhältnis von Signal (sytematischer Variabilität) zu Rauschen
(unsystematischer Variabilität)
verstanden werden:
\begin{equation}
\sqrt{\mbox{Stichprobengröße}}\left(\frac{\mbox{Signal}}{\mbox{Rauschen}}\right)
= \sqrt{n}\left(\frac{\bar{\ups} - \mu_0}{S}\right)
\end{equation}
* Die T-Teststastitik ist eine skalare Deskription des Effekt vs. Variabilität Verhältnisses eines Datensatzes.
* In der T-Teststatistik wird die Effektgröße in Einheiten der Stichprobenstandardabweichung gemessen:
\begin{itemize}
\footnotesize
\item[$\circ$] $T = 1 \Leftrightarrow \sqrt{n}(\bar{\ups} - \mu_0) = 1 S$
\item[$\circ$] $T = 2 \Leftrightarrow \sqrt{n}(\bar{\ups} - \mu_0) = 2 S$
\end{itemize}

# Einstichproben-T-Test | (2) Definition und Analyse der Teststatistik
\footnotesize
\begin{definition}[Nichtzentrale $t$-Zufallsvariable]
\justifying
$T$ sei eine Zufallsvariable mit Ergebnisraum $\mathbb{R}$ und WDF
\begin{multline}
p : \mathbb{R} \to \mathbb{R}_{>0}, t \mapsto p(t) :=
\frac{1}{2^{\frac{n-1}{2}}\Gamma\left(\frac{n}{2} \right)(n \pi)^{\frac{1}{2}}} \\
\times \int_{0}^\infty \tau^{\frac{n-1}{2}} \exp\left(-\frac{\tau}{2}\right)
\exp\left(-\frac{1}{2}\left(t \left(\frac{\tau}{n}\right)^{\frac{1}{2}} - \delta \right)^2 \right)\,d\tau.
\end{multline}
Dann sagen wir, dass $T$ einer
nichtzentralen $t$-Verteilung mit Nichtzentralitätsparameter $\delta$ und
Freiheitsgradparameter $n$ unterliegt und nennen $T$ eine \textit{nichtzentrale
$t$-Zufallsvariable mit Nichtzentralitätsparameter $\delta$ und
Freiheitsgradparameter $n$}. Wir kürzen dies mit $t(\delta, n)$ ab. Die WDF einer
nichtzentralen $t$-Zufallsvariable bezeichnen wir mit
$t(T;\delta,n)$. Die KVF und inverse KVF einer nichtzentralen $t$-Zufallsvariable
bezeichnen wir mit $\Psi(\cdot; \delta, n)$ und $\Psi^{-1}(\cdot; \delta, n)$, respektive.
\end{definition}
Bemerkungen

* Eine nichtzentrale $t$-Zufallsvariable mit $\delta = 0$ ist eine $t$-Zufallsvariable.
* Es gilt also $t(T;0,n) = t(T;n)$.
* Weiterhin gelten $\Psi(T;0,n) = \Psi(T;n)$ und $\Psi^{-1}(T;0,n) = \Psi^{-1}(T;n)$
* Die funktionale Form der WDF findet sich zum Beispiel in @lehmann_1986, Seite 254, Gl. (80).


# Einstichproben-T-Test | (2) Definition und Analyse der Teststatistik
Wahrscheinlichkeitsdichtefunktionen nichtzentraler $t$-Verteilungen

```{r, echo = F, eval = F}
options(warn=-1)                                                                 # warning off
t_min     = -5                                                                   # Minimum T-Wert
t_max     = 30                                                                   # Maximum T-Wert
t_res     = 1e3                                                                  # T-Wert Auflösung
t         = seq(t_min, t_max, len = t_res)                                       # T-Raum
delta     = c(0,5,15)                                                            # Nichtzentralitätsparameter
n         = c(5, 30)                                                             # Freiheitsgrade
p         = cbind(
            matrix(dt(t, n[1], delta[1]),nrow=length(t)),
            matrix(dt(t, n[2], delta[1]),nrow=length(t)),
            matrix(dt(t, n[1], delta[2]),nrow=length(t)),
            matrix(dt(t, n[2], delta[2]),nrow=length(t)),
            matrix(dt(t, n[1], delta[3]),nrow=length(t)),
            matrix(dt(t, n[2], delta[3]),nrow=length(t)))

# Visualisierung
dev.new()
graphics.off()
library(latex2exp)
par(
family      = "sans",
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)
matplot(
t,
p,
type        = "l",
lty         = c(1,2,1,2,1,2),
col         = c("gray10", "gray10", "gray50", "gray50", "gray70", "gray70"),
lwd         = 2,
xlab        = "T",
ylab        = "",
ylim        = c(0,.4),
main        = TeX("$t(T;\\delta,n)$"))
legend(
18,
.4,
c(TeX("$\\delta = 0 , \\,\\,\\, n = 5$"),
  TeX("$\\delta = 0 , \\,\\,\\, n = 30$"),
  TeX("$\\delta = 5 , \\,\\,\\, n = 5$"),
  TeX("$\\delta = 5 , \\,\\,\\, n = 30$"),
  TeX("$\\delta = 15, \\, n = 5$"),
  TeX("$\\delta = 15, \\, n = 30$")),
lty         = c(1,2,1,2,1,2),
col         = c("gray10", "gray10", "gray50", "gray50", "gray70", "gray70"),
lwd         = 2,
bty         = "n",
seg.len     = 1.75)
fdir        =  file.path(getwd(), "12_Abbildungen")
dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_nichtzentrale_t_verteilung.pdf"),
width       = 7,
height      = 4.5)
```

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_nichtzentrale_t_verteilung.pdf")
```

# Einstichproben-T-Test | (2) Definition und Analyse der Teststatistik
\footnotesize
\begin{theorem}[Nichtzentrale T-Transformation]
\normalfont
\justifying
$\ups \sim N(\mu,1)$ sei eine normalverteilte Zufallsvariable, $U \sim \chi^2(n)$
sei eine $\chi^2$ Zufallsvariable mit Freiheitsgradparameter $n$, und $\ups$ und
$U$ seien unabhängige Zufallsvariablen. Dann ist die Zufallsvariable
\begin{equation}
T := \frac{\ups}{\sqrt{U/n}}
\end{equation}
eine nichtzentrale $t$-Zufallsvariable mit Nichtzentralitätsparameter $\mu$ und
Freiheitsgradparameter $n$, also $T \sim t(\mu,n)$.
\end{theorem}
\vspace{-2mm}
Bemerkung

* Wir verzichten auf einen Beweis.

```{r, echo = F, eval = F}
# figure parameters
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex.main    = 1.2)

# simulation parameters
mu          = 5                                                                  # expectation parameter
n           = 5                                                                  # degrees of freedom parameter
ns          = 1e5                                                                # number of samples


# X sample
X           = rnorm(ns,mu,1)                                                     # ns samples of X \sim N(0,1)
x_min       = 0                                                                  # minimum x-value
x_max       = 10                                                                 # maximum x-value
x_res       = 1e3                                                                # x-space resolution
x           = seq(x_min, x_max, len = x_res)                                     # x-space
p_X         = dnorm(x,mu, 1)                                                     # x density

# histogram and density
hist(
X,
breaks      = 50,
col         = "gray90",
prob        = TRUE,
xlim        = c(x_min,x_max),
ylim        = c(0,.5),
xlab        = "x",
ylab        =  "",
main        = TeX("$\\upsilon \\sim N(5,1)$"))
lines(
x,
p_X,
lwd         = 2,
col         = "darkorange")

# chi^2 sample
U           = rchisq(ns,n)                                                       # ns samples of U \sim \chi^2(n)
u_min       = 1e-5                                                               # minimum z-value
u_max       = 20                                                                 # maximum z-value
u_res       = 1e3                                                                # u-space resolution
u           = seq(u_min, u_max, len = u_res)                                     # u-space
p_U         = dchisq(u,n)                                                        # u density

# histogram and density
hist(
U,
breaks      = 100,
col         = "gray90",
prob        = TRUE,
xlim        = c(u_min, u_max),
ylim        = c(0,0.2),
xlab        = "u",
ylab        = "",
main        = TeX("$U \\sim \\chi^2(5)$"))
lines(
u,
p_U,
lwd   = 2,
col   = "darkorange")

# Noncentral T-transformation
Tee         = X/(sqrt(U/n))                                                      # element-wise vector arithmetic
Tee         = Tee[!abs(Tee) > 30]                                                # mildly censored sample for good histogram performance
t_min       = 0                                                                  # minimum t-value
t_max       = 20                                                                 # maximum t-value
t_res       = 1e3                                                                # t-space resolution
t           = seq(t_min,t_max,len = t_res)                                       # t-space
p_T         = dt(t,n,mu)                                                         # t density


# histogram and density
hist(
Tee,
breaks      = 100,
col         = "gray90",
prob        = TRUE,
xlim        = c(t_min, t_max),
ylim        = c(0,0.3),
xlab        = "t",
ylab        = "",
main        = TeX("$T = \\upsilon/\\sqrt{U/n} \\sim \\t(5,5)$"))
lines(
t,
p_T,
lwd         = 2,
col         = "darkorange")
fdir        =  file.path(getwd(), "12_Abbildungen")
dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_nichtzentrale_t_transformation.pdf"),
width       = 7,
height      = 3)
```

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_nichtzentrale_t_transformation.pdf")
```

# Einstichproben-T-Test | (2) Definition und Analyse der Teststatistik
\footnotesize
\begin{theorem}[Verteilung der T-Teststatistik]
\justifying
\normalfont
$\ups_1,...,\ups_n \sim N(\mu,\sigma^2)$ sei die Stichprobe eines Normalverteilungmodells,
$\bar{\ups}$ sei das Stichprobenmittel, $S$ sei die Stichprobenstandardabweichung,
und es sei $\mu_0 \in \mathbb{R}$. Dann ist die  T-Teststatistik
\begin{equation}
T := \sqrt{n}\left(\frac{\bar{\ups} - \mu_0}{S} \right)
\end{equation}
eine nichtzentrale $t$-Zufallsvariable mit Nichtzentralitätsparameter
\begin{equation}
d = \sqrt{n}\left(\frac{\mu - \mu_0}{\sigma} \right)
\end{equation}
und Freiheitsgradparameter $n-1$, es gilt also $T \sim t(d,n-1)$
\end{theorem}

Bemerkung

* Wir verzichten auf einen Beweis.

# Einstichproben-T-Test | (2) Definition und Analyse der Teststatistik
T-Teststatistik bei $n = 12, \mu = 3, \sigma^2 = 2, \mu_0 = 0$
\vspace{8mm}

```{r, echo = F, eval = F}
library(latex2exp)
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(1,2),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex.main    = .9)

# simulation parameters
mu          = 3                                                                  # expectation parameter
sigsqr      = 2                                                                  # variance parameter
n           = 12                                                                 # degrees of freedom parameter
mu_0        = 0                                                                  # null hypothesis parameter
ns          = 1e4                                                                # number of samples

# simulation
X1          = rep(NaN,ns)                                                        # X_1 array
Tee         = rep(NaN,ns)                                                        # T Statistic array
for(i in 1:ns){
  X         = rnorm(n,mu,sqrt(sigsqr))                                           # Stichprobenrealisation
  X1[i]     = X[1]                                                               # X_1 Realisation
  Tee[i]    = sqrt(n)*(mean(X) - mu_0)/sd(X)                                     # T-Teststatistik
}

# X_1 Sample
x_min       = -6                                                                 # minimum x-value
x_max       = 12                                                                 # maximum x-value
x_res       = 1e3                                                                # x-space resolution
x           = seq(x_min, x_max, len = x_res)                                     # x-space
p_X         = dnorm(x, mu, sqrt(sigsqr))                                         # x density
hist(
X1,
breaks      = 50,
col         = "gray90",
prob        = TRUE,
xlim        = c(x_min,x_max),
ylim        = c(0,.3),
xlab        = "x",
ylab        =  "",
main        = TeX("$\\upsilon_1 \\sim N(\\mu,\\sigma^2)$"))
lines(
x,
p_X,
lwd         = 2,
col         = "darkorange")

# T-Teststatistik Sample
t_min       = 0                                                                  # minimum t-value
t_max       = 20                                                                 # maximum t-value
t_res       = 1e3                                                                # t-space resolution
t           = seq(t_min,t_max,len = t_res)                                       # t-space
d           = sqrt(n)*(mu - mu_0)/sqrt(sigsqr)                                   # noncentrality parameter
p_T         = dt(t,n-1,d)                                                        # t density
hist(
Tee,
breaks      = 100,
col         = "gray90",
prob        = TRUE,
xlim        = c(t_min, t_max),
ylim        = c(0,0.25),
xlab        = "t",
ylab        = "",
main        = TeX("$T = \\sqrt{n}\\left(\\frac{\\bar{\\upsilon}_{n} - \\mu_0}{S_{n}}\\right) \\sim \\t(d,n-1)$"))
lines(
t,
p_T,
lwd         = 2,
col         = "darkorange")
fdir        =  file.path(getwd(), "12_Abbildungen")
dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_t_teststatistik.pdf"),
width       = 8,
height      = 4)
```

```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_t_teststatistik.pdf")
```

# Einstichproben-T-Test | (3) Definition des Tests
\vspace{5mm}

Vor dem Hintergrund des statistischen Modells des Einstichproben-T-Tests betrachten
wir die einfache Nullhypothese und die zusammengesetzte Alternativhypothese
\begin{equation}
H_0 : \mu = \mu_0 \Leftrightarrow \Theta_0 := \{\mu_0\}
\mbox{ und }
H_1 : \mu \neq \mu_0 \Leftrightarrow \Theta_1 := \mathbb{R} \setminus \{\mu_0\},
\end{equation}
respektive, sowie die oben definierte T-Teststatistik
\begin{equation}
T := \sqrt{n}\left(\frac{\bar{\ups} - \mu_0}{S}\right).
\end{equation}
**Wir definieren nun den zweiseitigen Einstichproben-T-Test**
\begin{equation}
\phi(\ups) := 1_{\{|T| \ge k\}} =
{\begin{cases}
1 & |T| \ge k \\
0 & |T|  <  k
\end{cases}}.
\end{equation}

# Einstichproben-T-Test | (4) Analyse der Testgütefunktion
\vspace{1cm}

\small
\begin{theorem}[Testgütefunktion]
\justifying
\normalfont
$\phi$ sei der im obend definierte Test. Dann ist die Testgütefunktion von $\phi$ gegeben durch
\begin{equation}
q_{\phi} : \mathbb{R} \to [0,1],
\mu \mapsto q_{\phi}(\mu)
:= 1 - \Psi(k;d_\mu,n-1) + \Psi(-k;d_\mu,n-1)
\end{equation}
wobei $\Psi(\cdot; d_\mu, n-1)$  die KVF der nichtzentralen $t$-Verteilung mit
Nichtzentralitätsparameter
\begin{equation}
d_\mu := \sqrt{n}\left(\frac{\mu - \mu_0}{\sigma}\right)
\end{equation}
und Freiheitsgradparameter $n-1$ bezeichnet.
\end{theorem}
Bemerkungen

* Wir visualisieren die Testgütefunktion unten in Abhängigkeit von $k$.

# Einstichproben-T-Test | (4) Analyse der Testgütefunktion

\center Testgütefunktion $q_\phi$ für $\sigma^2 = 9, \mu_0 = 4, n = 12$ und $k = 1,2,3$.
\vspace{2mm}
\begin{equation*}
\quad q_{\phi}(\mu) = \mathbb{P}_\mu(\phi = 1)
\end{equation*}

```{r, echo = F, eval = F}
dev.new()
graphics.off()
library(latex2exp)
par(
family      = "sans",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.1,
cex.main    = 1.1)

# Parameter
mu_0        = 4
n           = 12
sigsqr      = 9
sigma       = sqrt(9)
k           = c(1,2,3)
mu          = matrix(seq(0, 8,len = 1e3), nrow = 1e3)
d           = sqrt(n)*(mu - mu_0)/sigma
q_mu        = cbind(matrix(1-pt(k[1],n-1,d)+ pt(-k[1],n-1,d),nrow=length(mu)),
                    matrix(1-pt(k[2],n-1,d)+ pt(-k[2],n-1,d),nrow=length(mu)),
                    matrix(1-pt(k[3],n-1,d)+ pt(-k[3],n-1,d),nrow=length(mu)))

# Visualisierung
matplot(
mu,
q_mu,
type        = "l",
lty         = c(1,2,3),
col         = "black",
lwd         = 2,
xlab        = "",
ylab        = "",
ylim        = c(0,1.05),
)
lines(
4,
0,
pty         = "p",
pch         = 16,
xpd         = TRUE
)
legend(
6,
.4,
c("k = 1", "k = 2", "k = 3"),
lty         = c(1,2,3),
col         = "black",
bty         = "n"
)
text(8.3,-.01, TeX("$\\mu$")                        , cex = 1.1, xpd = TRUE)
text(4  ,-.25, TeX("$H_0\\,:\\, \\mu = \\mu_0$")    , cex = 1.1, xpd = TRUE)
text(2  ,-.35, TeX("$H_1\\,:\\, \\mu \\neq \\mu_0$"), cex = 1.1, xpd = TRUE)
text(6  ,-.35, TeX("$H_1\\,:\\, \\mu \\neq \\mu_0$"), cex = 1.1, xpd = TRUE)
fdir        =  file.path(getwd(), "12_Abbildungen")
dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_t_test_ungerichtet_gütefunktion.pdf"),
width       = 7,
height      = 4)
```

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_t_test_ungerichtet_gütefunktion.pdf")
```

# Einstichproben-T-Test | (4) Analyse der Testgütefunktion
\setstretch{1.2}

\footnotesize
\underline{Beweis}

Die Testgütefunktion des betrachteten Test im vorliegenden Testszenario ist
definiert als
\begin{equation}
q_{\phi} : \mathbb{R} \to [0,1],
\mu \mapsto q_{\phi}(\mu) := \mathbb{P}_{\mu}(\phi = 1).
\end{equation}
Da die Wahrscheinlichkeiten für $\phi = 1$ und dafür, dass  die zugehörige
Teststatistik im Ablehnungsbereich des Tests liegt gleich sind, benötigen wird
die also zunächst die Verteilung der Teststatistik. Wir haben oben bereits
gesehen, dass die T-Teststatistik
\begin{equation}
T := \sqrt{n}\left(\frac{\bar{\ups} - \mu_0}{S} \right)
\end{equation}
unter der Annahme $\ups_1,...,\ups_n \sim N(\mu,\sigma^2)$ nach einer nichtzentralen
$t$-Verteilung $t(d,n-1)$ mit Nichtzentralitätsparameter
\begin{equation}
d_\mu := \sqrt{n}\left(\frac{\mu - \mu_0}{\sigma}\right)
\end{equation}
verteilt ist. Der Ablehnungsbereich des zweiseitigen T-Tests ergibt sich zu
\begin{equation}
A  = \,]-\infty, -k]\, \cup \,]k,\infty[.
\end{equation}
\vfill

# Einstichproben-T-Test | (4) Analyse der Testgütefunktion
\setstretch{1.2}

\footnotesize
\underline{Beweis (fortgeführt)}

Mit diesem Ablehungsbereich ergibt sich dann
\begin{align}
\begin{split}
q_\phi(\mu)
& = \mathbb{P}_{\mu}(\phi = 1)                                                   \\
& = \mathbb{P}_{\mu}\left(T \in ]-\infty, -k]\,
                         \cup \,]k,\infty[ \right)                               \\
& = \mathbb{P}_{\mu}\left(T \in ]-\infty, -k]\right)
  + \mathbb{P}_{\mu}\left(T \in [k,\infty[ \right)                               \\
& = \mathbb{P}_{\mu}(T \le -k)  + \mathbb{P}_{\mu}(T \ge k)                      \\
& = \mathbb{P}_{\mu}(T \le -k)  + (1-\mathbb{P}_{\mu}(T \le k))                  \\
& = 1 - \mathbb{P}_{\mu}(T \le k)  + \mathbb{P}_{\mu}(T \le - k)                 \\
& = 1 - \Psi(k; d_\mu, n-1)  + \Psi(-k;d_\mu,n-1),
\end{split}
\end{align}
wobei $\Psi(\cdot; d_\mu,n-1)$ die KVF der nichtzentralen T-Verteilung mit
Nichtzentralitätsparameter $d_\mu$ und Freiheitsgradparameter $n-1$ bezeichnet.

$\hfill\Box$
\vfill

# Einstichproben-T-Test | (5) Testumfangkontrolle
\small
\begin{theorem}[Testumfangkontrolle]
\justifying
\normalfont
$\phi$ sei der oben definierte Test. Dann ist $\phi$ ein
Level-$\alpha_0$-Test mit Testumfang $\alpha_0$, wenn der kritische Wert
definiert ist durch
\begin{equation}
k_{\alpha_0} := \Psi^{-1}\left(1 - \frac{\alpha_0}{2}; n-1 \right),
\end{equation}
wobei $\Psi^{-1}(\cdot; n-1)$ die inverse KVF der $t$-Verteilung mit $n-1$
Freiheitsgraden ist.
\end{theorem}

\footnotesize
\underline{Beweis}

Damit der betrachtete Test ein Level-$\alpha_0$-Test ist, muss bekanntlich
$q_\phi(\mu) \le \alpha_0$ für alle $\mu \in \{\mu_0\}$, also hier $q_\phi(\mu_0)
\le \alpha_0$, gelten. Weiterhin ist der Testumfang des betrachteten Tests durch
$\alpha = \max_{\mu \in \{\mu_0\}} q_\phi(\mu)$, also hier durch $\alpha =
q_\phi(\mu_0)$ gegeben. Wir  müssen also zeigen, dass die Wahl von $k_{\alpha_0}$
garantiert, dass $\phi$ ein Level-$\alpha_0$-Test mit Testumfang $\alpha_0$ ist.
Dazu merken wir zunächst an, dass für $\mu = \mu_0$ gilt, dass
\begin{align}
\begin{split}
q_\phi(\mu_0)
& =  1 - \Psi(k;d_{\mu_0},n-1) + \Psi(-k;d_{\mu_0},n-1)                          \\
& =  1 - \Psi(k;0,n-1) + \Psi(-k;0,n-1)                                          \\
& =  1 - \Psi(k;n-1) + \Psi(-k;n-1),                                             \\
\end{split}
\end{align}
wobei $\Psi(\cdot;d,n-1)$ und $\Psi(\cdot;n-1)$ die KVF der nichtzentralen
$t$-Verteilung mit Nichtzentralitätsparameter $d$ und Freiheitsgradparameter $n-1$
sowie der $t$-Verteilung mit Freiheitsgradparameter $n-1$, respektive, bezeichnen.


# Einstichproben-T-Test | (5) Testumfangkontrolle
\footnotesize
\underline{Beweis (fortgeführt)}

Sei nun also $k := k_{\alpha_0}$. Dann gilt
\begin{align}
\begin{split}
q_\phi(\mu_0)
& = 1 - \Psi(k_{\alpha_0};n-1) + \Psi(-k_{\alpha_0};n-1)                             \\
& = 1 - \Psi(k_{\alpha_0};n-1) + (1 - \Psi(k_{\alpha_0};n-1)                         \\
& = 2(1-\Psi(k_{\alpha_0};n-1))                                                      \\
& = 2\left(1-\Psi\left(\Psi^{-1}\left(1- \frac{\alpha_0}{2} , n-1\right), n-1\right)\right) \\
& = 2\left(1 - 1 + \alpha_0/2\right)                          \\
& = \alpha_0,
\end{split}
\end{align}
wobei die zweite Gleichung mit der Symmetrie der $t$-Verteilung folgt. Es folgt
also direkt, dass bei der Wahl von $k = k_{\alpha_0}$, $q_\phi(\mu_0)\le \alpha_0$
ist und der betrachtete Test somit ein Level-$\alpha_0$-Test ist. Weiterhin
folgt direkt, dass der Testumfang des betrachteten Tests bei der Wahl von
$k = k_{\alpha_0}$ gleich $\alpha_0$ ist.

# Einstichproben-T-Test | (5) Testumfangkontrolle
\small
\center Wahl von $k_{\alpha_0} := \Psi^{-1}(1- \frac{\alpha_0}{2}; n-1)$ mit $n =12$, $\alpha_0 := 0.05$ und Ablehnungsbereich
\vspace{3mm}

```{r, echo = F, eval = F}
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(1,2),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)

# Parameter
n           = 12
alpha_0     = 0.05                                                               # Konfidenzniveau
k_alpha_0   = qt(1 - alpha_0/2, n-1)                                             # kritischer Wert
t           = seq(-4,4,length=1e4)                                               # T-Statistikwerte
Pt          = pt(t,n-1)                                                          # T-Statistik KVF für H_0
pt          = dt(t,n-1)                                                          # T-Statistik WDF für H_0

# KVF Perspektive
plot(                                                                            # original density function
t,
Pt,
type        = "l",
ylab        = " ",
ylim        = c(0,1),
main        = TeX("$\\Psi$"))

lines(
k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

lines(
min(t),
1 - alpha_0/2,
type        = "p",
pch         = 16,
xpd         = TRUE)

arrows(
x0          = min(t),
y0          = 1 - alpha_0/2,
x1          = k_alpha_0,
y1          = 1 - alpha_0/2,
col         = "darkorange",
angle       = 45,
length      = .1)

arrows(
x0          = k_alpha_0,
y0          = 1-alpha_0/2,
x1          = k_alpha_0,
y1          = 0,
col         = "darkorange",
angle       = 45,
length      = .1)

text(k_alpha_0, -.25 , TeX("$\\k_{\\alpha_0}$"), xpd = TRUE)
text(-3       , 1.05 , TeX("$1 - \\alpha_0/2$"), xpd = TRUE)


# WDF Perspektive
plot(
t,
pt,
type        = "l",
ylab        = " ",
ylim        = c(0,.4),
main        = TeX("$t$"))

polygon(
c(t[t  <= -k_alpha_0] , 0, 0),
c(pt[t <= -k_alpha_0],  min(t), -k_alpha_0),
col = "gray90",
border = NA)

polygon(
c(t[t  >= k_alpha_0] , max(t), k_alpha_0),
c(pt[t >= k_alpha_0],       0, 0),
col = "gray90",
border = NA)

lines(
seq(min(t), -k_alpha_0, len = 1e2),
rep(0,1e2),
type        = "l",
lwd         = 5,
col         = "darkorange")

lines(
seq(k_alpha_0, max(t), len = 1e2),
rep(0,1e2),
type        = "l",
lwd         = 5,
col         = "darkorange")

lines(
- k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE,)

lines(
k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

text(-k_alpha_0,-.11, TeX("$-\\k_{\\alpha_0}$"), xpd = TRUE)
text( k_alpha_0,-.11, TeX("$\\k_{\\alpha_0}$") , xpd = TRUE)
text( 3, .05, TeX("$P(T >= k_{\\alpha_0}) = \\alpha_0/2$"), xpd = TRUE, cex = .8, col = "gray50")
text(-3, .05, TeX("$P(T <= k_{\\alpha_0}) = \\alpha_0/2$"), xpd = TRUE, cex = .8, col = "gray50")

fdir        =  file.path(getwd(), "12_Abbildungen")
dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_t_test_ungerichtet_testumfangkontrolle.pdf"),
width       = 8,
height      = 4)
```

```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_t_test_ungerichtet_testumfangkontrolle.pdf")
```


# Einstichproben-T-Test | (5) Testumfangkontrolle
\justifying
\noindent
\vspace{1mm}
Praktisches Vorgehen
\small

* \justifying Man nimmt an, dass ein vorliegender Datensatz $y_1,...,y_n$ eine
Realisation von $\ups_1,...,\ups_n \sim N(\mu,\sigma^2)$ mit unbekannten Parametern
$\mu$ und $\sigma^2 > 0$ ist.

* Man möchte entscheiden ob für ein $\mu_0 \in \mathbb{R}$ eher
$H_0 : \mu = \mu_0$ oder $H_1: \mu \neq \mu_0$ zutrifft.
\item Man wählt ein Signifikanzlevel $\alpha_0$ und bestimmt den
zugehörigen Freiheitsgradparameter-abhängigen kritischen Wert $k_{\alpha_0}$.
Zum Beispiel gilt bei Wahl von $\alpha_0  := 0.05$ und $n=12$, also
Freiheitsgradparameter 11, dass $k_{0.05}=\Psi^{-1}(1 - 0.05/2; 11) \approx 2.20$
ist.

* Anhand von $n, \mu_0, \bar{\ups}$ und $s_n$ berechnet man die
Realisierung der T-Teststatistik
\begin{equation}
t := \sqrt{n}\left(\frac{\bar{y} - \mu_0}{s}\right)
\end{equation}

* Wenn $t$ größer-gleich $k_{\alpha_0}$ ist oder wenn $t$ kleiner-
gleich $-k_{\alpha_0}$ ist, lehnt man die Nullhypothese ab, andernfalls lehnt
man sie nicht ab. Die oben entwickelte Theorie  garantiert dann, dass
man in höchstens $\alpha_0 \cdot 100$ von $100$ Fällen die Nullhypothese
fälschlicherweise ablehnt.

# Einstichproben-T-Test | (5) Testumfangkontrolle
Simulation des praktischen Vorgehens
\vspace{2mm}

\tiny
\setstretch{1}
```{r}
# Modellparameter
n         = 12                                           # Anzahl der Datenpunkte
mu        = 0                                            # wahrer, aber unbekannter, Erwartungswertparameter
sigsqr    = 2                                            # wahrer, aber unbekannter, Varianzmatrixparameter

# Testparameter
mu_0      = 0                                            # H_0 Hypothesenparameter, hier \mu = \mu_0
alpha_0   = 0.05                                         # Signifikanzlevel
k_alpha_0 = qt(1-alpha_0/2,n-1)                          # kritischer Wert

# Simulation der Testumfangkontrolle
set.seed(1)                                              # Random number generator seed
nsim      = 1e6                                          # Anzahl Simulationen
phi       = rep(NaN,nsim)                                # Testentscheidungsarray
for(j in 1:nsim){                                        # Simulationsiterationen
    y      = rnorm(n,mu,sigsqr)                          # \ups_i \sim N(\mu,\Sigma), i = 1,...,n
    y_bar  = mean(y)                                     # Stichprobenmittel
    s      = sd(y)                                       # Stichprobenstandardabweichung
    Tee    = sqrt(n)*((y_bar - mu_0)/s)                  # T-Teststatistik
    if(abs(Tee) > k_alpha_0){                            # Test 1_{|t| >= k_alpha_0}
        phi[j] = 1                                       # Ablehnen von H_0
    } else {
        phi[j] = 0                                       # Nicht Ablehnen von H_0
    }
}

# Ausgabe
cat("Kritischer Wert              =", k_alpha_0,
    "\nGeschätzter Testumfang alpha =", mean(phi))
```

# Einstichproben-T-Test | (6) Analyse der Powerfunktion
\vfill
\justifying

\small
Wir betrachten die Testgütefunktion
\begin{equation}
q_\phi : \mathbb{R} \to [0,1],
\mu \mapsto q_\phi(\mu)
:= 1 - \Psi(k_{\alpha_0}; d_\mu, n-1) + \Psi(-k_{\alpha_0}; d_\mu, n-1)
\end{equation}
bei kontrolliertem Testumfang, also für $k_{\alpha_0} := \Psi^{-1}(1-\alpha_0/2;n-1)$
mit festem $\alpha_0$ als Funktion des Nichtzentralitätsparameters und des
Stichprobenumfangs. Namentlich hängt hier $k_{\alpha_0}$ auch von $n$ ab.

Es ergibt sich die bivariate reellwertige Funktion
\begin{equation}
\pi : \mathbb{R} \times \mathbb{N} \to [0,1],
(d,n) \mapsto
\pi(d,n) := 1 - \Psi(k_{\alpha_0}; d, n-1) + \Psi(-k_{\alpha_0}; d, n-1)
\end{equation}
Bei festgelegten $\alpha_0$ hängt die Powerfunktion des zweiseitigen T-Tests
mit einfacher Nullhypothese also vom unbekannten Wert $d$ und von der
Stichprobengröße $n$ ab. Wir visualisieren diese Abhängigkeiten untenstehend.
\vfill

# Einstichproben-T-Test | (6) Analyse der Powerfunktion
\small
Powerfunktion für $\alpha_0 = 0.05$

```{r, eval = F, echo = F}

# circumvent RMarkdown Beamer Interaction
graphics.off()
fdir        =  file.path(getwd(), "12_Abbildungen")
dev.new()
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.2,
cex.main    = 1.2)

# Szenariospezifikation
d_min       = -5                                # d Minimum
d_max       =  5                                # d Maximum
d_res       = 50                                # d Auflösung
d           = seq(d_min, d_max, len = d_res) # d Raum
n_min       = 1                                 # n Minimum
n_max       = 30                                # n Maximum
n_res       = 50                                # n Auflösung
n           = seq(n_min,n_max, len = n_res)     # n Raum


# Visualisierung
alpha_0   = 0.05
pi        = matrix(rep(NaN, d_res*n_res), nrow = d_res)
for(i in 1:d_res){
  for(j in 1:n_res){
    k_alpha_0 = qt(1 - alpha_0/2, n[j]-1)
    pi[i,j]   = 1-pt(k_alpha_0, n[j]-1, d[i])+pt(-k_alpha_0, n[j]-1, d[i])
  }
}
persp(
d,
n,
pi,
d           = 1,
col         = "gray90",
theta       = 21,
phi         = 30,
lwd         = .5,
scale       = T,
ticktype    = "detailed",
r           = 1.5)
dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_t_test_ungerichtet_power_005.pdf"),
width       = 7,
height      = 7)

```

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_t_test_ungerichtet_power_005.pdf")
```

# Einstichproben-T-Test | (6) Analyse der Powerfunktion
\small
Powerfunktion für $\alpha_0 = 0.001$

```{r, eval = F, echo = F}
# circumvent RMarkdown Beamer Interaction
graphics.off()
fdir        =  file.path(getwd(), "12_Abbildungen")
dev.new()
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.2,
cex.main    = 1.2)

# Szenariospezifikation
d_min       = -5                                # d Minimum
d_max       =  5                                # d Maximum
d_res       = 50                                # d Auflösung
d           = seq(d_min, d_max, len = d_res) # d Raum
n_min       = 1                                 # n Minimum
n_max       = 30                                # n Maximum
n_res       = 50                                # n Auflösung
n           = seq(n_min,n_max, len = n_res)     # n Raum

# Visualisierung
alpha_0   = 0.001
pi        = matrix(rep(NaN, d_res*n_res), nrow = d_res)
for(i in 1:d_res){
  for(j in 1:n_res){
    k_alpha_0 = qt(1 - alpha_0/2, n[j]-1)
    pi[i,j]   = 1-pt(k_alpha_0, n[j]-1, d[i])+pt(-k_alpha_0, n[j]-1, d[i])
  }
}
persp(
d,
n,
pi,
d           = 1,
col         = "gray90",
theta       = 21,
phi         = 30,
lwd         = .5,
scale       = T,
ticktype    = "detailed",
r           = 1.5)
dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_t_test_ungerichtet_power_0001.pdf"),
width       = 7,
height      = 7)

```

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_t_test_ungerichtet_power_0001.pdf")
```

# Einstichproben-T-Test | (6) Analyse der Powerfunktion

\small
\justifying

Powerfunktionen für $\mu_0 = 0$
\vspace{2mm}

```{r, echo = F, eval = F}
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(2,2),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1)

# Szenariospezifikation
mu_0      = 0                                 # einfache Nullhypothese
d_min     = -5                                # d  Minimum
d_max     =  5                                # d Maximum
d_res     = 50                                # d Auflösung
d         = seq(d_min, d_max, len = d_res)    # d Raum
n_min     = 2                                 # n Minimum
n_max     = 50                                # n Maximum
n_res     = 1e2                               # n Auflösung
n         = seq(n_min,n_max, len = n_res)     # n Raum


# Funktion von d, n = 12, \alpha_0 = 0.05
alpha_0   = 0.05
n_fix     = 12
k_alpha_0 = qt(1 - alpha_0/2, n_fix-1)
pi_d      = 1-pt(k_alpha_0, n_fix-1, d)+pt(-k_alpha_0, n_fix-1, d)
plot(
d,
pi_d,
type      = "l",
lwd       = 2,
ylim      = c(0,1),
ylab      = " ",
xlab      = TeX("$d$"),
main      = TeX("$\\pi(d,n = 12),\\, \\alpha_0 = 0.05$"))

# Funktion von d, n = 12, \alpha_0 = 0.001
alpha_0   = 0.001
n_fix     = 12
k_alpha_0 = qt(1-alpha_0/2, n_fix-1)
pi_d      = 1-pt(k_alpha_0, n_fix-1, d)+pt(-k_alpha_0, n_fix-1, d)
plot(
d,
pi_d,
type      = "l",
lwd       = 2,
ylim      = c(0,1),
ylab      = " ",
xlab      = TeX("$d$"),
main      = TeX("$\\pi(d,n = 12),\\, \\alpha_0 = 0.001$"))

# Funktion von n, d = 3, \alpha_0 = 0.05
alpha_0   = 0.05
d_fix     = 3
k_alpha_0 = qt(1-alpha_0/2, n-1)
pi_n      = 1-pt(k_alpha_0, n-1, d_fix)+pt(-k_alpha_0, n-1, d_fix)
plot(
n,
pi_n,
type      = "l",
lwd       = 2,
ylab      = " ",
ylim      = c(0,1),
xlab      = TeX("$n$"),
main      = TeX("$\\pi(d = 3,n),\\, \\alpha_0 = 0.05$"))

# Funktion von n, d = 3, \alpha_0 = 0.001
alpha_0   = 0.001
d_fix     = 3
k_alpha_0 = qt(1-alpha_0/2, n-1)
pi_n      = 1-pt(k_alpha_0, n-1, d_fix)+pt(-k_alpha_0, n-1, d_fix)
plot(
n,
pi_n,
type      = "l",
lwd       = 2,
ylab      = " ",
ylim      = c(0,1),
xlab      = TeX("$n$"),
main      = TeX("$\\pi(d = 3,n),\\, \\alpha_0 = 0.001$"))

dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_t_test_ungerichtet_powerfunktionen.pdf"),
width       = 8,
height      = 7)

```

```{r, echo = FALSE, out.width = "70%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_t_test_ungerichtet_powerfunktionen.pdf")
```

# Einstichproben-T-Test | (6) Analyse der Powerfunktion
Praktisches Vorgehen
\small

Mit größerem $n$ steigt die Powerfunktion des Tests an

* Ein großer Stichprobenumfang ist besser als ein kleiner Stichprobenumfang.

* Kosten für die Erhöhung des Stichprobenumfangs werden aber nicht berücksichtigt.

$\Rightarrow$ Die Theorie statistischer Hypothesentests ist nicht besonders lebensnah.

\vspace{1mm}

Die Powerfunktion hängt vom wahren, aber unbekannten, Parameterwert $d = \sqrt{n}(\mu - \mu_0)/\sigma$ ab.

$\Rightarrow$ Wenn man $d$ schon kennen würde, würde man den Test nicht durchführen.

\vspace{1mm}

Generell wird folgendes Vorgehen favorisiert

* Man legt das Signifikanzlevel $\alpha_0$ fest und evaluiert die Powerfunktion.

* Man wählt einen Mindestparameterwert $d^*$, den man mit $\pi(d,n) = \beta$ detektieren möchte.

* Ein konventioneller Wert ist $\beta = 0.8$.

* Man liest die für $\pi(d = d^*,n) = \beta$ nötige Stichprobengröße $n$ ab.


# Einstichproben-T-Test | (6) Analyse der Powerfunktion
Praktisches Vorgehen
\vspace{5mm}

```{r, echo = F}

# Szenariospezifikation
sigma     = 1                                                       # bekanntes \sigma
mu_0      = 0                                                       # einfache Nullhypothese
n_min     = 2                                                       # n Minimum
n_max     = 20                                                      # n Maximum
n_res     = 1e2                                                     # n Auflösung
n         = seq(n_min,n_max, len = n_res)                           # n Raum
alpha_0   = 0.05                                                    # Signifikanzlevel

# Poweranalyse
d_fix     = 3                                                       # fester Nichtzentralitätsparameter
k_alpha_0 = qt(1-alpha_0/2, n-1)                                    # kritische Werte
pi_n      = 1-pt(k_alpha_0, n-1, d_fix)+pt(-k_alpha_0, n-1, d_fix)  # Powerfunktion
beta      = 0.8                                                     # gewünschter Powerfunktionswert
i         = 1                                                       # Indexinitialisierung
n_min     = NaN                                                     # minimales n Initialisierung
while(pi_n[i] < beta){                                              # Solange \pi(d*,n) < \beta
    n_min = n[i]                                                    # Aufnahme des minimal nötigen ns
    i     = i + 1                                                   # und Erhöhung des Indexes
}
# cat("Minimal nötiges n =", ceiling(n_min))                          # Ausgabe
```

```{r, echo = F, eval = F}
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.2,
cex.main    = 1.2)

plot(
n,
pi_n,
type        = "l",
lwd         = 2,
ylab        = " ",
ylim        = c(0,1),
xlab        = TeX("$n$"),
main        = TeX("$\\pi(d = 3,n)\\, für \\,\\alpha_0 = 0.05,\\, \\mu_0 = 0"))

lines(
2,
beta,
type        = "p",
pch         = 16,
xpd         = TRUE)

lines(
n_min,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

arrows(
x0          = min(n),
y0          = beta,
x1          = n_min,
y1          = beta,
col         = "darkorange",
angle       = 20,
length      = .1)

arrows(
x0          = n_min,
y0          = beta,
x1          = n_min,
y1          = 0,
col         = "darkorange",
angle       = 20,
length      = .1)
text(3 , 0.85 , TeX("$\\beta$") ,xpd = TRUE, cex = 1.2)
text(20 ,.05  , TeX("$n_{opt}") ,xpd = TRUE, cex = 1.2)

dev.copy2pdf(
file        = file.path(fdir, "wtfi_12_t_test_ungerichtet_stichprobengröße.pdf"),
width       = 6,
height      = 5)

```

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_t_test_ungerichtet_stichprobengröße.pdf")
```


#
\setstretch{2.4}
\large
\vfill
Grundlegende Definitionen

Einstichproben-T-Test

**p-Werte**

Konfidenzintervalle und Hypothesentests

Anwendungsbeispiel

Selbstkontrollfragen
\vfill

# p-Werte
Motivation

\small
\begin{itemize}
\justifying
\item  Es werde ein zweiseitiger Einstichproben-T-Test mit $n = 12$ und $\alpha_0 = 0.05$ durchgeführt.
\begin{itemize}
\small
\item[$\circ$]  $H_0$ wird abgelehnt, wenn $|T| \ge 2.20$.
\end{itemize}
\item Nehmen wir an, es werde $t = 2.26$ beobachtet.
\begin{itemize}
\small
\item[$\circ$] Das Testergebnis lautet "$H_0$ Ablehnen".
\end{itemize}
\item Nehmen wir an, es werde $t = 3.81$ beobachtet.
\begin{itemize}
\small
\item[$\circ$] Das Testergebnis lautet "$H_0$ Ablehnen".
\end{itemize}
\item Der alleinige Bericht des Testergebnis supprimiert interessante Information.
\item[$\quad \Rightarrow$] Neben der Testumfangkontrolle durch z.B. $\alpha_0 = 0.05$
ist es daher üblich, alle Werte von $\alpha_0$ anzugeben, für die ein
Level-$\alpha_0$-Test zum Ablehnen von $H_0$ führen würde.
\begin{itemize}
\justifying
\small
\item[$\circ$] Bei $t = 2.26$ würde $H_0$ für jedes $\alpha_0$ mit $2.26 \ge \Psi^{-1}\left(1-\frac{\alpha_0}{2};11\right)$ abgelehnt werden.
\item[$\circ$] Bei $t = 3.81$ würde $H_0$ für jedes $\alpha_0$ mit $3.81 \ge \Psi^{-1}\left(1-\frac{\alpha_0}{2};11\right)$ abgelehnt werden.
\end{itemize}
\item Das kleinste Signifikanzlevel $\alpha_0$, bei dem man $H_0$ basierend auf
einem Wert der Teststatistik ablehnen würde, wird \textit{p-Wert} des Wertes 
der Teststatistik genannt.
\end{itemize}


# p-Werte
\small
\begin{definition}[p-Wert]
\justifying
$\phi$ sei ein kritischer Wert-basierter Test. Der \textit{p-Wert} ist das
kleinste Signifikanzlevel $\alpha_0$, bei welchem man die Nullhypothese
basierend auf einem vorliegendem Wert der Teststatistik ablehnen würde.
\end{definition}
\small
Beispiel (Zweiseitiger Einstichproben-T-Test mit einfacher Nullhypothese)

\footnotesize
* Bei $T = t$ würde $H_0$ für jedes $\alpha_0$ mit $|t| \ge \Psi^{-1}\left(1- \frac{\alpha_0}{2};n-1\right)$
abgelehnt werden. Für diese $\alpha_0$ gilt, wie unten gezeigt,
\begin{equation}
\alpha_0 \ge 2 \mathbb{P}(T \ge |t|).
\end{equation}
* Das kleinste $\alpha_0 \in [0,1]$ mit $\alpha_0 \ge 2 \mathbb{P}(T \ge |t|)$ ist
dann $\alpha_0 = 2 \mathbb{P}(T \ge |t|)$, also folgt
\begin{equation}
\mbox{p-Wert} =  2 \mathbb{P}(T \ge |t|) = 2(1 - \Psi(|t|;n-1)).
\end{equation}
* Zum Beispiel ist bei $n = 12$ für $T = 2.26$ der p-Wert $0.045$, 
für $T = -2.26$ ist der p-Wert auch $0.045$, für $T = 3.81$ ist der p-Wert 
$0.003$ und für $T = -3.81$ ist der p-Wert auch $0.003$.


# p-Werte
\small
Beispiel (Zweiseitiger Einstichproben-T-Test mit einfacher Nullhypothese)

\footnotesize
* \itemsep2mm \justifying Es bleibt zu zeigen, dass gilt
\begin{equation}
|t| \ge \Psi^{-1}(1- \frac{\alpha_0}{2}; n-1)
\Leftrightarrow
\alpha_0 \ge 2 \mathbb{P}(T \ge |t|)
\end{equation}

* Dies aber folgt aus \footnotesize \vspace{-2mm}
\begin{align}
\begin{split}
|t|
& \ge \Psi^{-1}\left(1 - \frac{\alpha_0}{2}; n-1\right)
\\\Leftrightarrow
\Psi(|t|; n-1)
& \ge \Psi\left(\Psi^{-1}\left(1 - \frac{\alpha_0}{2}; n-1\right); n-1\right)
\\\Leftrightarrow
\Psi(|t|; n-1)
& \ge 1 - \frac{\alpha_0}{2}
\\\Leftrightarrow
\mathbb{P}(T \le |t|)
& \ge 1 - \frac{\alpha_0}{2}
\\\Leftrightarrow
\frac{\alpha_0}{2}
& \ge 1 - \mathbb{P}(T \le |t|)
\\\Leftrightarrow
\frac{\alpha_0}{2}
& \ge \mathbb{P}(T \ge |t|)
\\\Leftrightarrow
\alpha_0
& \ge 2 \mathbb{P}(T \ge |t|).
\end{split}
\end{align}


# p-Werte
\small
Beispiel (Zweiseitiger Einstichproben-T-Test mit einfacher Nullhypothese)
\vspace{8mm}

```{r, echo = F, eval = F}
library(latex2exp)
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(1,2),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.1,
cex.main    = 1.1)

# Modell
n           = 12                                                                 # Anzahl Datenpunkte
tee         = seq(-5,5,length=1e4)                                               # T-Statistikwerte
pt          = dt(t,n-1)                                                          # T-Statistik WDF
Tee         = c(2.26, 3.81)                                                      # Beispiel T-Werte
P           = 2*(1 - pt(Tee,n-1))                                                # Beispiel P-Werte

# Visualisierung
for(i in seq_along(Tee)){

  # WDF
  plot(
  tee,
  pt,
  type        = "l",
  ylab        = " ",
  xlab        = "t",
  ylim        = c(0,.4),
  main        = sprintf("t = %1.2f, p = %1.3f", Tee[i], P[i]))

  # AUCs
  polygon(
  c(tee[tee  <= -Tee[i]] , 0, 0),
  c(pt[tee <= -Tee[i]],  min(tee), -Tee[i]),
  col = "red",
  border = NA)
  polygon(
  c(tee[tee  >= Tee[i]] , max(tee), Tee[i]),
  c(pt[tee >= Tee[i]],       0, 0),
  col = "red",
  border = NA)

  # T-Werte
  lines(
  -Tee[i],
  0,
  type        = "p",
  pch         = 16,
  xpd         = TRUE)
  lines(
  Tee[i],
  0,
  type        = "p",
  pch         = 16,
  xpd         = TRUE)

  # p-Werte
  text(0, .05, TeX("$2(1 - \\Psi(|t|;n-1))$"), xpd = TRUE, cex = 1, col = "red")

}

dev.copy2pdf(
file        = file.path("12_Abbildungen/wtfi_12_p_werte.pdf"),
width       = 10,
height      = 5)

```
\vspace{3mm}
```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_p_werte.pdf")
```


# p-Werte
\small
Bemerkungen
\begin{itemize}
\justifying
\item[$\circ$] p-Werte spiegeln die Antwort auf die intuitive Frage wie
wahrscheinlich es im Frequentistischen Sinne wäre, den beobachteten oder einen
extremeren Wert der Teststatistik unter der Annahme eines Nullmodels zu
observieren.
\item[$\circ$] p-Werte sind ist extrem populär, ihre uninformierte Benutzung ist aber auch sehr umstritten.
\footnotesize
\item[$\rightarrow$] \href{https://www.tandfonline.com/toc/utas20/73/sup1}{The American Statistician (2019) Statistical Inference in the 21st Century: A World Beyond p < 0.05}
\small
\item[$\circ$]  p-Werte werden, wie Hypothesentestergebnisse generell, leider oft überinterpretiert.
\item[$\circ$]  Es gibt basierend auf dem Gesagten keinen Grund dies anzunehmen, trotzdem vorsorglich:
\begin{itemize}
\begin{footnotesize}
\item[$\circ$] p-Werte quantifizieren nicht die Wahrscheinlichkeit, dass die Nullhypothese wahr ist.
\item[$\circ$] Aufgrund von $p < 0.05$ sollte man nicht glauben, dass ein Effekt existiert.
\item[$\circ$] Aufgrund von $p > 0.05$ sollte man nicht glauben, dass ein Effekt nicht existiert.
\end{footnotesize}
\end{itemize}
\item[$\circ$] p-Werte sind eine Möglichkeit ein Signal-zu-Rauschen Verhältnis zu quantifizieren.
\item[$\circ$] p-Werte sind eine Möglichkeit Unsicherheit zu quantifizieren.
\end{itemize}

#
\setstretch{2.4}
\large
\vfill
Grundlegende Definitionen

Einstichproben-T-Test

p-Werte

**Konfidenzintervalle und Hypothesentests**

Anwendungsbeispiel

Selbstkontrollfragen
\vfill

# Konfidenzintervalle und Hypothesentests
\small
\begin{theorem}[Dualität von Konfidenzintervallen und Hypothesentest]
\justifying
\normalfont
$\ups = \ups_1,...,\ups_n \sim p_\theta$ sei eine Stichprobe mit Ergebnisraum
$\mathcal{Y}$ und Parameterraum $\Theta$. Weiterhin sei $[G_u(\ups), G_o(\ups)]$
ein $\delta$-Konfidenzintervall für $\theta$. Dann ist der Hypothesentest
\begin{equation}
\phi_\theta : \mathcal{Y} \to \{0,1\},
y \mapsto \phi(y)
:=
\begin{cases}
0, & [G_u(y), G_o(y)] \ni    \theta_0 \\
1, & [G_u(y), G_o(y)] \niton \theta_0 \\
\end{cases}
\end{equation}
ein Test vom Signifikanzlevel $\alpha_0 = 1 - \delta$ für die Hypothesen
\begin{equation}
\Theta_0 := \{\theta_0\} \mbox{ und } \Theta_1 := \Theta \setminus \{\theta_0\}.
\end{equation}
\end{theorem}

\footnotesize
\underline{Beweis}
\vspace{1mm}

Aufgrund der einfachen Nullhypothese und somit $\alpha_0 = \alpha$ folgt
\begin{equation}
\alpha_0
= \alpha
= \mathbb{P}_{\theta_0}(\phi(\ups) = 1)
= \mathbb{P}_{\theta_0}([G_u(y), G_o(y)] \niton \theta)
= 1 - \mathbb{P}_{\theta_0}([G_u(y), G_o(y)] \ni \theta)
= 1 - \delta.
\end{equation}

Bemerkung

* Mit $\delta$-Konfidenzintervallen kann man also Hypothesentests mit Signifikanzlevel $\alpha_0 = 1-\delta$ konstruieren.

# Konfidenzintervalle und Hypothesentests
\small
Beispiel (Konstruktion eines Hypothesentests aus einem Konfidenzintervall)

\footnotesize
Wir haben bereits gesehen, dass für eine Stichprobe $\ups = \ups_1,...,\ups_n \sim N(\mu,\sigma^2)$,
$\delta \in ]0,1[$ und 
\begin{equation}
t_\delta := \Psi^{-1}\left(\frac{1 + \delta}{2}; n-1 \right)
\end{equation}
ein $\delta$-Konfidenzintervall durch
\begin{equation}
\kappa :=
\left[\bar{\ups} - \frac{S}{\sqrt{n}}t_\delta,\bar{\ups} + \frac{S}{\sqrt{n}}t_\delta\right].
\end{equation}
definiert ist. Mit der Dualität von Konfidenzintervallen und Hypothesentests 
können wir also folgenden Test für die Hypothesen $\Theta_0 = \{\mu_0\}$
und $\Theta_1 = \mathbb{R} \setminus \mu_0$ definieren:
\begin{equation}
\phi : \mathcal{Y} \to \{0,1\},
y \mapsto \phi(y)
:=
\begin{cases}
0, & \left[\bar{\ups} - \frac{S}{\sqrt{n}}t_\delta,\bar{\ups} + \frac{S}{\sqrt{n}}t_\delta\right]
           \ni \mu_0
          \\ \\
1, &\left[\bar{\ups} - \frac{S}{\sqrt{n}}t_\delta,\bar{\ups} + \frac{S}{\sqrt{n}}t_\delta\right]
          \niton \mu_0
          \\
\end{cases}
\end{equation}
Dann gilt
\begin{align}
\begin{split}
\mathbb{P}_{\mu_0}\left(\phi(\ups) = 1 \right)
& = 1 - \mathbb{P}_{\mu_0}\left(\phi(\ups) = 0 \right) \\
& = 1 - \mathbb{P}_{\mu_0}\left(
            \left[\bar{\ups} - \frac{S}{\sqrt{n}}t_\delta,
                  \bar{\ups} + \frac{S}{\sqrt{n}}t_\delta\right]
            \ni \mu_0\right) \\
& = 1 - \delta.
\end{split}
\end{align}
und wir haben gezeigt, dass $\phi$ ein Test vom Signifikanzlevel
$\alpha_0 = 1 -\delta$ ist.

# Konfidenzintervalle und Hypothesentests
\vspace{2mm}
Simulation der Dualität von Konfidenzintervallen und Hypothesentests
\vspace{1mm}
\tiny
\setstretch{.9}
```{r}
# Modellformulierung
n       = 12                                          # Stichprobengröße
mu      = 2                                           # wahrer, aber unbekannter, Erwartungswertparameter
sigsqr  = 1                                           # wahrer, aber unbekannter, Varianzparameter

# Konfidenzintervallparameter und Testparameter
delta   = 0.95                                        # Konfidenzbedingung
t_delta = qt((1+delta)/2, n-1)                        # \Psi^{-1}((\delta + 1)/2, n-1)
mu_0    = mu                                          # Nullhypothesenparameter 

# Simulationen
set.seed(1)                                           # random number generator seed
ns      = 1e2                                         # Anzahl Simulationen
y_bar   = rep(NaN,ns)                                 # Stichprobenmittelarray
s       = rep(NaN,ns)                                 # Stichprobenstandardabweichungarray
kappa   = matrix(rep(NaN,2*ns), ncol = 2)             # Konfidenzintervallarray
kfn     = rep(NaN,ns)                                 # Überdeckungsindikatorarray
phi     = rep(NaN,ns)                                 # Testarray
for(i in 1:ns){                                       # Simulationsiterationen
  # Stichprobenrealisation und Konfidezintervallevaluation  
  y          = rnorm(n,mu_0,sqrt(sigsqr))             # Stichprobenrealisierung
  y_bar[i]   = mean(y)                                # Stichprobenmittel
  s[i]       = sd(y)                                  # Stichprobenstandardabweichung
  kappa[i,1] = y_bar[i] - (s[i]/sqrt(n))*t_delta      # untere KI Grenze
  kappa[i,2] = y_bar[i] + (s[i]/sqrt(n))*t_delta      # obere KI Grenze

  # Überdeckungs- und Testevaluation
  if(kappa[i,1] <= mu_0 & mu_0 <= kappa[i,2]){
      kfn[i] = 1} else{kfn[i] = 0}                    # Überdeckungsindikatorevaluation
  if(kappa[i,1] <= mu_0 & mu_0 <= kappa[i,2]){
      phi[i] = 0} else{phi[i] = 1}}                    # Testevaluation

# Ausgabe
cat(   "Geschätztes Konfidenzniveau =", mean(kfn),
     "\nGeschätzter Testumfang      =", mean(phi))
```

# Konfidenzintervalle und Hypothesentests
\vspace{1mm}
Simulation der Dualität von Konfidenzintervallen und Hypothesentests
\vspace{1mm}
```{r, echo = F, eval = F}
# Visualisierung
dev.new()
graphics.off()
par(
family      = "sans",
bty         = "l",
mfcol       = c(2,1),
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.1,
cex.main    = 1.1)

# Konfidenzintervallvisualisierung
nv          = 1e2                                                                # Simulationsanzahl für Visualisierung
I           = rep(NaN,ns  )                                                      # Nicht überdeckende KIs für Visualisierung
I[kfn == 0] = 3.5                                                                # Markerpositions
plot(
1:ns,
y_bar,
type    = "p",
ylim    = c(0,4),
xlim    = c(0,102),
xlab    = "Simulationen",
ylab    = "",
pch     =  19,
cex     =  .5,
main    = "Konfidenzintervalle")
arrows(
x0      = 1:ns,
y0      = kappa[1:ns,1],
x1      = 1:nv,
y1      = kappa[1:ns,2],
code    = 3,
angle   = 90,
length  = 0.01,
lwd     = .7)
abline(
mu,
0,
col      = "gray80",
lty      = 1)
lines(
1:ns,
I,
type    = "p",
pch     = 13,
col     = "darkorange")

# Testvisualisierung
plot(
1:ns,
phi,
type    = "p",
ylim    = c(-.2,1.2),
xlim    = c(0,102),
las     = 1,
xlab    = "Simulationen",
ylab    = "",
pch     =  16,
cex     =  .6,
yaxp    = c(0,1,1),
main    = "Hypothesentests")
dev.copy2pdf(
file        = file.path("12_Abbildungen/wtfi_12_dualität.pdf"),
width       = 9,
height      = 6)
```
```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_dualität.pdf")
```

#
\setstretch{2.4}
\large
\vfill
Grundlegende Definitionen

Einstichproben-T-Test

p-Werte

Konfidenzintervalle und Hypothesentests

**Anwendungsbeispiel**

Selbstkontrollfragen
\vfill

# Anwendungsbeispiel
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("12_Abbildungen/wtfi_12_messplan.pdf")
```

# Einstichproben-T-Test
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression
\vspace{2mm}

\small
Wir legen für die BDI Score Reduktion $\ups_i$ der $i$ten von $n$ Patient:innen  das Modell
\begin{equation}
\ups_{i} = \mu + \varepsilon_{i} \mbox{ mit } \varepsilon_{i} \sim N(0,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n
\end{equation}
zugrunde. 

Wir erklären die BDI Reduktion $\ups_i$ der $i$ten Patient:in also 
mithilfe einer über die Gruppe von Patient:innen identischen BDI Score 
Reduktion $\mu$ als Effekt der Therapieintervention und einer Patient:innen-spezifischen 
normalverteilten BDI Score Reduktionsabweichung $\varepsilon_{i}$, die sich
aus sehr vielen additiven Prozessen zusammensetzt, für die wir also eine 
Normalverteilungsannahme treffen, und deren Varianz wir mit $\sigma^2$ parameterisieren.

Vor dem Hintergrund dieses Modells evaluieren wir die drei Standardprobleme der 
Frequentistischen Inferenz für den Effekt der Therapieintervention $\mu$:

(1) Was ist unserer Schätzung für den Effekt $\mu$ der Therapie auf die BDI Score Reduktion?
(2) Welches 95%-Konfidenzintervall ist mit dieser Schätzung von $\mu$ assoziiert?
(3) Entscheiden wir uns sinnvoller Weise für die Nullhypothese $\mu = 0$?


# Anwendungsbeispiel
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression
\vspace{2mm}

\footnotesize
```{r}
fname = file.path(getwd(), "12_Hypothesentests.csv")
D     = read.table(fname, sep = ",", header = T)
```
\vspace{2mm}

```{r, echo = F}
knitr::kable(D, "pipe", align = "rr")  
```

# Anwendungsbeispiel
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression
\vspace{2mm}
\tiny
\setstretch{1}
```{r}
# Einlesen und Auswahl der Daten
fname     = file.path(getwd(), "12_Hypothesentests.csv")  # Dateiname
D         = read.table(fname, sep = ",", header = T)      # Dataframe
y         = D$BDI.Reduktion                               # Datenrealisation
n         = length(y)                                     # Anzahl Datenpunkte

# Parameterschätzung
y_bar      = mean(y)                                      # Stichprobenmittel
mu_hat     = y_bar                                        # Unverzerrte Maximum-Likelihood Schätzung

# Konfidenzintervallevaluation 
delta    = 0.95                                           # Konfidenzlevel
t_delta  = qt((1+delta)/2,n-1)                            # \Psi^-1((\delta + 1)/2, n-1)
G_u      = y_bar - (sd(y)/sqrt(n))*t_delta                # untere KI Grenze
G_o      = y_bar + (sd(y)/sqrt(n))*t_delta                # obere  KI Grenze

# Testevaluation
mu_0      = 0                                             # H_0 Hypothesenparameter, hier \mu = \mu_0
alpha_0   = 0.05                                          # Signifikanzlevel
k_alpha_0 = qt(1-alpha_0/2,n-1)                           # kritischer Wert
Tee       = sqrt(n)*((y_bar - mu_0)/sd(y))                # T-Teststatistik
if(abs(Tee) > k_alpha_0){phi = 1} else {phi = 0}          # Test 1_{|t| >= k_alpha_0}                             

# p-Wert Evaluation
p         = 2*(1 - pt(Tee,n-1))                           # p-Wert
```

# Anwendungsbeispiel
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression

\vspace{4mm}
\footnotesize
\setstretch{1.2}

```{r}
# Ausgabe
cat("Parameterschätzwert    =", mu_hat,
    "\n95%-Konfidenzintervall =", G_u, G_o,
    "\nSignifikanzlevel       =", alpha_0,
    "\nKritischer Wert        =", k_alpha_0,
    "\nTeststatistik          =", Tee,
    "\nTestwert               =", phi,
    "\np-Wert                 =", p)
```

# Anwendungsbeispiel
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression

\vspace{2mm}
\small
Frequentistische Inferenz mit R's `t.test()` Funktion 
\vspace{2mm}

\footnotesize
```{r}
t.test(y)         # Anwendung der in Einheiten (1) bis (12) entwickelten Theorie
```

# Anwendungsbeispiel
Beispiel | Evidenzbasierte Evaluation von Psychotherapie bei Depression

\small
\noindent (1) Was ist unserer Schätzung für den wahren, aber unbekannten, Effekt $\mu$ der Therapie?

* Unsere Schätzung für den Therapieeffekt ist eine BDI Reduktion von $\hat{\mu} = 3.17$.

\small
\noindent (2) Welches 95%-Konfidenzintervall ist mit dieser Schätzung von $\mu$ assoziiert?

* Das 95%-Konfidenzintervall für den Therapieeffekt ist eine BDI Reduktion $[0.81,5.53]$.

\small
\noindent (3) Entscheiden wir uns sinnvoller Weise für die Nullhypothese $\mu = 0$?

* Bei einem Signifikanzlevel von $\alpha_0 = 0.05$ lehnen wir die Nullhypothese $\mu = 0$ ab ($p = 0.01$).

Aus datenwisschenschaftlicher Sicht sind Ergebnis und Unsicherheit dieses Szenarios 
im Frequentistischen Sinne nun quantifiziert. Die Interpretation des Ergebnisses inklusive
des Mehrwerts der Therapie bei einer geschätzten BDI Score Reduktion von $\approx 3$ 
obliegt der Klinischen Psychologie.


#
\setstretch{2.4}
\large
\vfill
Grundlegende Definitionen

Einstichproben-T-Test

p-Werte

Konfidenzintervalle und Hypothesentests

Anwendungsbeispiel

**Selbstkontrollfragen**
\vfill

# Selbstkontrollfragen
\setstretch{1.8}
\footnotesize
1. Erläutern Sie die grundlegende Logik statistischer Hypothesentests.
2. Geben Sie die Definition statistischer Hypothesen und eines Testszenarios wieder.
3. Definieren Sie die Begriffe der einfachen und zusammengesetzten Hypothesen.
4. Definieren Sie die Begriffe der einseitigen und zweiseitigen Hypothesen.
5. Definieren Sie den Begriff des Tests.
6. Definieren Sie den Begriff des Standardtests.
7. Definieren Sie den Begriff des kritischen Bereichs eines Tests.
8. Definieren Sie den Begriff des Ablehungsbereichs eines Tests.
9. Definieren Sie den Begriff des kritischen Wert-basierten Tests.
10. Definieren Sie richtige Testentscheidungen, Typ I Fehler und Typ II Fehler.
11. Definieren Sie die Testgütefunktion.
12. Erläutern Sie die Bedeutung der Testgütefunktion im Rahmen der Konstruktion statistischer Tests.
13. Definieren Sie die Begriffe des Signifikanniveaus und des Level-$\alpha_0$-Tests.
14. Definieren Sie den Begriff des Testumfangs.
15. Erläutern Sie die prinzipielle Strategie zur Wahl von Null- und Alternativhypothesen in der Wissenschaft.
16. Erläutern Sie zentrale Schritte zur Konstruktion eines Hypothesentests.

# Selbstkontrollfragen
\setstretch{1.8}
\footnotesize
17. \justifying Formulieren Sie das statistische Modell eines Einstichproben-T-Tests.
18. Formulieren Sie die einfache Nullhypothese und zusammengesetzte Alternativhypothese dieses Tests.
19. Definieren Sie den zweiseitigen Einstichproben-T-Test (ZETT).
20. Skizzieren Sie qualitativ die Testgütefunktionen eines ZETTs für verschiedene kritische Werte.
21. Wie muss der kritische Wert eines ZETTs definiert sein, damit der Test ein Level-$\alpha_0$-Test ist?
22. Skizzieren Sie qualitativ die Bestimmung des kritischen Wertes $k_{\alpha_0}$ bei einem zws Einstichproben-T-Test.
23. Erläutern Sie das praktische Vorgehen zur Durchführung eines ZETTs.
24. Von welchen Werten hängt die Powerfunktion eines ZETTs ab?
25. Skizzieren Sie qualitativ die Powerfunktion des ZETTs bei fester Stichprobengröße.
26. Skizzieren Sie qualitativ die Powerfunktion des ZETTs bei festem Erwartungswertparameter.
27. Erläutern Sie das favorisierte praktische Vorgehen zur Durchführung einer Poweranalyse.
28. Erläutern Sie die Motivation zur Auswertung von p-Werten.
29. Definieren Sie den Begriff des p-Werts.
30. Geben Sie das Theorem zur Dualität von Konfidenzintervallen und Hypothesentests wieder.
31. Erläutern Sie die Dualität von Konfidenzintervallen und Hypothesentests.


# References
\footnotesize